{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN8HzMII28LRq0cbDEDAKfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bmparent/AutoGPT/blob/master/bicameral_compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "_vN1RbWURD4j",
        "outputId": "05397706-f97e-4987-d38a-c85331342ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING THE NOETIC ENGINE...\n",
            ">>> Subject: Lorenz Attractor (Deterministic Chaos)\n",
            ">>> Philosophy: 'Compress by predicting the unpredictable'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "'B' format requires 0 <= number <= 255",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-334020890.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNoeticEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchaos_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;31m# 2. Analyze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-334020890.py\u001b[0m in \u001b[0;36mcompress\u001b[0;34m(self, data_generator, output_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Write [Flag=0][Count]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0moutput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                 \u001b[0mchunk_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: 'B' format requires 0 <= number <= 255"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RESERVOIR (THE \"SUBCONSCIOUS\" WORLD MODEL)\n",
        "# ==============================================================================\n",
        "\n",
        "class ReservoirCompute:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine that 'dreams' the telemetry.\n",
        "    Based on Echo State Networks (Jaeger, 2001).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=500, spectral_radius=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "\n",
        "        # FIXED WEIGHTS (The DNA of the system - shared by Encoder/Decoder)\n",
        "        np.random.seed(42) # Deterministic universe\n",
        "\n",
        "        # W_in: Project sensory data into high-dimensional mental space\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs))\n",
        "\n",
        "        # W_res: The internal chaotic dynamics (synapses)\n",
        "        self.W_res = np.random.uniform(-0.5, 0.5, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Tune the \"Chaos Level\" (Spectral Radius)\n",
        "        # < 1.0 = Fades to silence\n",
        "        # > 1.0 = Explodes into chaos\n",
        "        # ~ 1.0 = \"Edge of Chaos\" (Where life exists)\n",
        "        eigenvalues = np.linalg.eigvals(self.W_res)\n",
        "        max_eig = np.max(np.abs(eigenvalues))\n",
        "        self.W_res = self.W_res * (spectral_radius / max_eig)\n",
        "\n",
        "        # State Vector (The current \"thought\")\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "\n",
        "        # Readout Weights (The \"Conscious\" understanding)\n",
        "        # This is the ONLY thing we train/update.\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "    def listen(self, input_vector):\n",
        "        \"\"\" Projects reality into the mind (Update State) \"\"\"\n",
        "        # x(t) = tanh( W_in*u(t) + W_res*x(t-1) )\n",
        "        pre_activation = np.dot(self.W_in, input_vector) + np.dot(self.W_res, self.state)\n",
        "        self.state = np.tanh(pre_activation)\n",
        "\n",
        "    def dream(self) -> np.ndarray:\n",
        "        \"\"\" Predicts the next moment based on current state \"\"\"\n",
        "        # y(t) = W_out * x(t)\n",
        "        return np.dot(self.W_out, self.state)\n",
        "\n",
        "    def learn(self, target_vector, learning_rate=0.1):\n",
        "        \"\"\"\n",
        "        Epiphany: Update W_out to minimize surprise.\n",
        "        Using RLS (Recursive Least Squares) or simple Delta Rule for speed.\n",
        "        Simple Delta: W_out += rate * error * state.T\n",
        "        \"\"\"\n",
        "        prediction = self.dream()\n",
        "        error = target_vector - prediction\n",
        "\n",
        "        # Hebbian-style update\n",
        "        # We need to reshape state to (N,1) for outer product\n",
        "        update = np.outer(error, self.state)\n",
        "        self.W_out += learning_rate * update\n",
        "\n",
        "        return np.linalg.norm(error) # Return the magnitude of \"Surprise\"\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC ENCODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticEncoder:\n",
        "    def __init__(self, n_features):\n",
        "        self.brain = ReservoirCompute(n_features)\n",
        "        self.surprise_threshold = 0.05 # How much reality can deviate from the dream\n",
        "\n",
        "    def compress(self, data_generator, output_file):\n",
        "        # Header: NOET (Magic)\n",
        "        output_file.write(b'NOET')\n",
        "        output_file.write(struct.pack('<I', self.brain.n_inputs))\n",
        "\n",
        "        chunk_buffer = []\n",
        "\n",
        "        # Statistics\n",
        "        total_frames = 0\n",
        "        epiphanies = 0 # Updates sent\n",
        "\n",
        "        for frame in data_generator:\n",
        "            # 1. Ask the Brain: \"What happens next?\"\n",
        "            dream = self.brain.dream()\n",
        "\n",
        "            # 2. Compare with Reality\n",
        "            surprise = np.linalg.norm(frame - dream)\n",
        "\n",
        "            # 3. Decision: Is the Surprise meaningful?\n",
        "            if surprise > self.surprise_threshold:\n",
        "                # >>> EPIPHANY DETECTED <<<\n",
        "                # The world has changed in a way we didn't expect.\n",
        "                # We must teach the decoder's brain.\n",
        "\n",
        "                # We calculate the precise W_out update needed\n",
        "                # Ideally, we send the TARGET frame, and let the decoder run the 'learn' function.\n",
        "                # This ensures both brains stay synchronized.\n",
        "\n",
        "                # Packet: [Flag=1][Frame Data]\n",
        "                # We send the RAW frame that caused the surprise.\n",
        "                # The decoder will use this to run .learn() and sync up.\n",
        "\n",
        "                output_file.write(struct.pack('B', 1))\n",
        "                output_file.write(frame.astype(np.float32).tobytes())\n",
        "\n",
        "                # Update our local brain immediately\n",
        "                self.brain.listen(frame) # Update state\n",
        "                self.brain.learn(frame)  # Update weights\n",
        "                epiphanies += 1\n",
        "\n",
        "            else:\n",
        "                # >>> PREDICTABLE REALITY <<<\n",
        "                # The brain correctly predicted this.\n",
        "                # We send [Flag=0]. NO DATA.\n",
        "                # Actually, 1 bit per frame is too much.\n",
        "                # We should RLE (Run Length Encode) the silence.\n",
        "\n",
        "                chunk_buffer.append(0)\n",
        "\n",
        "                # Just update the state (Listening), but NO Learning (Weights stay same)\n",
        "                # Crucial: The decoder can only 'listen' to its own dream in this state.\n",
        "                self.brain.listen(frame)\n",
        "\n",
        "            # Flush RLE buffer if needed (Simplified for demo)\n",
        "            if len(chunk_buffer) > 255:\n",
        "                # Write [Flag=0][Count]\n",
        "                output_file.write(struct.pack('BB', 0, len(chunk_buffer)))\n",
        "                chunk_buffer = []\n",
        "\n",
        "            total_frames += 1\n",
        "\n",
        "        # Final flush\n",
        "        if chunk_buffer:\n",
        "            output_file.write(struct.pack('BB', 0, len(chunk_buffer)))\n",
        "\n",
        "        print(f\"\\n[Noetic Stats] Total Moments: {total_frames} | Epiphanies (Writes): {epiphanies}\")\n",
        "        print(f\"Cognitive Load: {epiphanies/total_frames*100:.2f}% (Percentage of reality that was surprising)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC DECODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticDecoder:\n",
        "    def decompress(self, input_file) -> Generator[np.ndarray, None, None]:\n",
        "        magic = input_file.read(4)\n",
        "        if magic != b'NOET': raise ValueError(\"Invalid Noetic Stream\")\n",
        "\n",
        "        n_inputs = struct.unpack('<I', input_file.read(4))[0]\n",
        "        brain = ReservoirCompute(n_inputs)\n",
        "\n",
        "        while True:\n",
        "            # Read Flag\n",
        "            header = input_file.read(1)\n",
        "            if not header: break\n",
        "            flag = struct.unpack('B', header)[0]\n",
        "\n",
        "            if flag == 1:\n",
        "                # >>> EPIPHANY (Read Frame, Learn) <<<\n",
        "                data = input_file.read(n_inputs * 4)\n",
        "                frame = np.frombuffer(data, dtype=np.float32)\n",
        "\n",
        "                # This frame is Truth.\n",
        "                yield frame\n",
        "\n",
        "                # Sync the brain\n",
        "                brain.listen(frame)\n",
        "                brain.learn(frame)\n",
        "\n",
        "            elif flag == 0:\n",
        "                # >>> DREAM (Read Count, Hallucinate) <<<\n",
        "                count = struct.unpack('B', input_file.read(1))[0]\n",
        "\n",
        "                for _ in range(count):\n",
        "                    # The decoder hallucinates the data\n",
        "                    dream = brain.dream()\n",
        "                    yield dream\n",
        "\n",
        "                    # Crucial: The brain feeds on its own dream to advance time\n",
        "                    # This is \"Closed-Loop Hallucination\"\n",
        "                    brain.listen(dream)\n",
        "\n",
        "# ==============================================================================\n",
        "# \"THE CHAOS SIMULATION\" (Testing the Philosophy)\n",
        "# ==============================================================================\n",
        "\n",
        "def chaos_generator(steps):\n",
        "    \"\"\"\n",
        "    Generates a Lorenz Attractor (Deterministic Chaos).\n",
        "    This is impossible for Zip/Linear methods to predict well.\n",
        "    \"\"\"\n",
        "    dt = 0.01\n",
        "    x, y, z = 0.1, 0.0, 0.0\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Lorenz Equations\n",
        "        dx = 10 * (y - x)\n",
        "        dy = x * (28 - z) - y\n",
        "        dz = x * y - (8/3) * z\n",
        "\n",
        "        x += dx * dt\n",
        "        y += dy * dt\n",
        "        z += dz * dt\n",
        "\n",
        "        # We project this 3D chaos into 128 dimensions via a random matrix\n",
        "        # simulating a complex sensor array reading a chaotic event\n",
        "        np.random.seed(42)\n",
        "        projection = np.random.randn(3, 128)\n",
        "        state = np.array([x, y, z])\n",
        "\n",
        "        # The sensor reading\n",
        "        sensors = np.dot(state, projection)\n",
        "\n",
        "        # Normalize roughly\n",
        "        sensors = sensors / 50.0\n",
        "\n",
        "        yield sensors.astype(np.float32)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\">>> INITIALIZING THE NOETIC ENGINE...\")\n",
        "    print(\">>> Subject: Lorenz Attractor (Deterministic Chaos)\")\n",
        "    print(\">>> Philosophy: 'Compress by predicting the unpredictable'\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    FEATURES = 128\n",
        "    FILENAME = \"mind_log.noet\"\n",
        "\n",
        "    # 1. Compress\n",
        "    encoder = NoeticEncoder(FEATURES)\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        encoder.compress(chaos_generator(STEPS), f)\n",
        "\n",
        "    # 2. Analyze\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"EPISTEMIC RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Raw Reality:    {raw_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Stored Wisdom:  {file_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Ratio:          {ratio:.2f}x\")\n",
        "\n",
        "    # 3. Verify (Did the brain understand the chaos?)\n",
        "    print(\"\\n>>> Dreaming the Chaos (Decompressing)...\")\n",
        "    decoder = NoeticDecoder()\n",
        "    mse = 0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        gen = chaos_generator(STEPS)\n",
        "        dec_gen = decoder.decompress(f)\n",
        "\n",
        "        for real, dream in zip(gen, dec_gen):\n",
        "            mse += np.mean((real - dream)**2)\n",
        "            count += 1\n",
        "\n",
        "    print(f\"Dream Fidelity (MSE): {mse/count:.6f}\")\n",
        "\n",
        "    os.remove(FILENAME)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RESERVOIR (THE \"SUBCONSCIOUS\" WORLD MODEL)\n",
        "# ==============================================================================\n",
        "\n",
        "class ReservoirCompute:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine that 'dreams' the telemetry.\n",
        "    Based on Echo State Networks (Jaeger, 2001).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=500, spectral_radius=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "\n",
        "        # FIXED WEIGHTS (The DNA of the system - shared by Encoder/Decoder)\n",
        "        np.random.seed(42)  # Deterministic universe\n",
        "\n",
        "        # W_in: Project sensory data into high-dimensional mental space\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs))\n",
        "\n",
        "        # W_res: The internal chaotic dynamics (synapses)\n",
        "        self.W_res = np.random.uniform(-0.5, 0.5, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Tune the \"Chaos Level\" (Spectral Radius)\n",
        "        # < 1.0 = Fades to silence\n",
        "        # > 1.0 = Explodes into chaos\n",
        "        # ~ 1.0 = \"Edge of Chaos\" (Where life exists)\n",
        "        eigenvalues = np.linalg.eigvals(self.W_res)\n",
        "        max_eig = np.max(np.abs(eigenvalues))\n",
        "        self.W_res = self.W_res * (spectral_radius / max_eig)\n",
        "\n",
        "        # State Vector (The current \"thought\")\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "\n",
        "        # Readout Weights (The \"Conscious\" understanding)\n",
        "        # This is the ONLY thing we train/update.\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "    def listen(self, input_vector: np.ndarray) -> None:\n",
        "        \"\"\"Projects reality into the mind (Update State).\"\"\"\n",
        "        # x(t) = tanh( W_in*u(t) + W_res*x(t-1) )\n",
        "        pre_activation = np.dot(self.W_in, input_vector) + np.dot(self.W_res, self.state)\n",
        "        self.state = np.tanh(pre_activation)\n",
        "\n",
        "    def dream(self) -> np.ndarray:\n",
        "        \"\"\"Predicts the next moment based on current state.\"\"\"\n",
        "        # y(t) = W_out * x(t)\n",
        "        return np.dot(self.W_out, self.state)\n",
        "\n",
        "    def learn(self,\n",
        "              target_vector: np.ndarray,\n",
        "              learning_rate: float = 0.1,\n",
        "              prediction: np.ndarray | None = None) -> float:\n",
        "        \"\"\"\n",
        "        Epiphany: Update W_out to minimize surprise.\n",
        "        Simple Delta: W_out += rate * error * state.T\n",
        "\n",
        "        - We optionally take 'prediction' so encoder/decoder can pass in the\n",
        "          exact dream used to compute surprise.\n",
        "        \"\"\"\n",
        "        if prediction is None:\n",
        "            prediction = self.dream()\n",
        "\n",
        "        error = target_vector - prediction\n",
        "\n",
        "        # Hebbian-style update (outer product)\n",
        "        update = np.outer(error, self.state)\n",
        "        self.W_out += learning_rate * update\n",
        "\n",
        "        return np.linalg.norm(error)  # Magnitude of \"Surprise\"\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC ENCODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticEncoder:\n",
        "    def __init__(self, n_features: int):\n",
        "        self.brain = ReservoirCompute(n_features)\n",
        "        self.surprise_threshold = 0.05  # How much reality can deviate from the dream\n",
        "\n",
        "    def compress(self,\n",
        "                 data_generator: Generator[np.ndarray, None, None],\n",
        "                 output_file) -> None:\n",
        "        # Header: NOET (Magic)\n",
        "        output_file.write(b'NOET')\n",
        "        output_file.write(struct.pack('<I', self.brain.n_inputs))\n",
        "\n",
        "        # Buffer for run-length encoding of predictable frames\n",
        "        chunk_buffer = []  # each element is just a placeholder; we use len()\n",
        "\n",
        "        # Statistics\n",
        "        total_frames = 0\n",
        "        epiphanies = 0  # Updates sent\n",
        "\n",
        "        for frame in data_generator:\n",
        "            # 1. Ask the Brain: \"What happens next?\"\n",
        "            dream = self.brain.dream()\n",
        "\n",
        "            # 2. Compare with Reality\n",
        "            surprise = np.linalg.norm(frame - dream)\n",
        "\n",
        "            # 3. Decision: Is the Surprise meaningful?\n",
        "            if surprise > self.surprise_threshold:\n",
        "                # >>> EPIPHANY DETECTED <<<\n",
        "                # The world has changed in a way we didn't expect.\n",
        "                # We must teach the decoder's brain.\n",
        "\n",
        "                # Flush any accumulated silence *before* writing epiphany\n",
        "                if chunk_buffer:\n",
        "                    count = len(chunk_buffer)   # guaranteed <= 255 due to cap below\n",
        "                    output_file.write(struct.pack('BB', 0, count))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "                # Packet: [Flag=1][Frame Data]\n",
        "                output_file.write(struct.pack('B', 1))\n",
        "                output_file.write(frame.astype(np.float32).tobytes())\n",
        "\n",
        "                # Learn from the SAME dream we just used for surprise\n",
        "                self.brain.learn(frame, prediction=dream)\n",
        "                self.brain.listen(frame)  # advance state with ground truth\n",
        "\n",
        "                epiphanies += 1\n",
        "\n",
        "            else:\n",
        "                # >>> PREDICTABLE REALITY <<<\n",
        "                # The brain correctly predicted this.\n",
        "                # We send [Flag=0] with RLE of how many frames were predictable.\n",
        "\n",
        "                chunk_buffer.append(0)  # Just track length\n",
        "\n",
        "                # Just update the state (Listening), but NO Learning (weights stay same)\n",
        "                self.brain.listen(frame)\n",
        "\n",
        "                # Flush RLE buffer if needed (max count 255 for single-byte)\n",
        "                # FIX: do it when count reaches 255, not when it exceeds it.\n",
        "                if len(chunk_buffer) == 255:\n",
        "                    output_file.write(struct.pack('BB', 0, 255))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "            total_frames += 1\n",
        "\n",
        "        # Final flush for any remaining predictable frames (1..254)\n",
        "        if chunk_buffer:\n",
        "            count = len(chunk_buffer)\n",
        "            output_file.write(struct.pack('BB', 0, count))\n",
        "\n",
        "        if total_frames > 0:\n",
        "            cognitive_load = epiphanies / total_frames * 100.0\n",
        "        else:\n",
        "            cognitive_load = 0.0\n",
        "\n",
        "        print(f\"\\n[Noetic Stats] Total Moments: {total_frames} | Epiphanies (Writes): {epiphanies}\")\n",
        "        print(f\"Cognitive Load: {cognitive_load:.2f}% (Percentage of reality that was surprising)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC DECODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticDecoder:\n",
        "    def decompress(self, input_file) -> Generator[np.ndarray, None, None]:\n",
        "        magic = input_file.read(4)\n",
        "        if magic != b'NOET':\n",
        "            raise ValueError(\"Invalid Noetic Stream\")\n",
        "\n",
        "        header = input_file.read(4)\n",
        "        if len(header) != 4:\n",
        "            raise ValueError(\"Truncated Noetic header\")\n",
        "        n_inputs = struct.unpack('<I', header)[0]\n",
        "\n",
        "        brain = ReservoirCompute(n_inputs)\n",
        "\n",
        "        while True:\n",
        "            # Read Flag\n",
        "            header = input_file.read(1)\n",
        "            if not header:\n",
        "                break  # End of stream\n",
        "\n",
        "            flag = struct.unpack('B', header)[0]\n",
        "\n",
        "            if flag == 1:\n",
        "                # >>> EPIPHANY (Read Frame, Learn) <<<\n",
        "                data = input_file.read(n_inputs * 4)\n",
        "                if len(data) != n_inputs * 4:\n",
        "                    raise ValueError(\"Truncated epiphany frame in stream\")\n",
        "                frame = np.frombuffer(data, dtype=np.float32)\n",
        "\n",
        "                # This frame is Truth.\n",
        "                yield frame\n",
        "\n",
        "                # Sync the brain: learn from this frame, then listen to it\n",
        "                dream = brain.dream()\n",
        "                brain.learn(frame, prediction=dream)\n",
        "                brain.listen(frame)\n",
        "\n",
        "            elif flag == 0:\n",
        "                # >>> DREAM (Read Count, Hallucinate) <<<\n",
        "                count_bytes = input_file.read(1)\n",
        "                if len(count_bytes) != 1:\n",
        "                    raise ValueError(\"Truncated RLE count in stream\")\n",
        "                count = struct.unpack('B', count_bytes)[0]\n",
        "\n",
        "                for _ in range(count):\n",
        "                    # The decoder hallucinates the data\n",
        "                    dream = brain.dream()\n",
        "                    yield dream\n",
        "\n",
        "                    # Crucial: The brain feeds on its own dream to advance time\n",
        "                    # This is \"Closed-Loop Hallucination\"\n",
        "                    brain.listen(dream)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown flag in stream: {flag}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# \"THE CHAOS SIMULATION\" (Testing the Philosophy)\n",
        "# ==============================================================================\n",
        "\n",
        "def chaos_generator(steps: int) -> Generator[np.ndarray, None, None]:\n",
        "    \"\"\"\n",
        "    Generates a Lorenz Attractor (Deterministic Chaos).\n",
        "    This is hard for simple linear methods to predict well.\n",
        "    \"\"\"\n",
        "    dt = 0.01\n",
        "    x, y, z = 0.1, 0.0, 0.0\n",
        "\n",
        "    # Projection fixed once (a standing sensor array)\n",
        "    np.random.seed(42)\n",
        "    projection = np.random.randn(3, 128)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Lorenz Equations\n",
        "        dx = 10 * (y - x)\n",
        "        dy = x * (28 - z) - y\n",
        "        dz = x * y - (8/3) * z\n",
        "\n",
        "        x += dx * dt\n",
        "        y += dy * dt\n",
        "        z += dz * dt\n",
        "\n",
        "        state = np.array([x, y, z])\n",
        "\n",
        "        # The sensor reading (project 3D chaos into 128D)\n",
        "        sensors = np.dot(state, projection)\n",
        "\n",
        "        # Normalize roughly\n",
        "        sensors = sensors / 50.0\n",
        "\n",
        "        yield sensors.astype(np.float32)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\">>> INITIALIZING THE NOETIC ENGINE...\")\n",
        "    print(\">>> Subject: Lorenz Attractor (Deterministic Chaos)\")\n",
        "    print(\">>> Philosophy: 'Compress by predicting the unpredictable'\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    FEATURES = 128\n",
        "    FILENAME = \"mind_log.noet\"\n",
        "\n",
        "    # 1. Compress\n",
        "    encoder = NoeticEncoder(FEATURES)\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        encoder.compress(chaos_generator(STEPS), f)\n",
        "\n",
        "    # 2. Analyze\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size if file_size > 0 else float('inf')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"EPISTEMIC RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Raw Reality:    {raw_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Stored Wisdom:  {file_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Ratio:          {ratio:.2f}x\")\n",
        "\n",
        "    # 3. Verify (Did the brain understand the chaos?)\n",
        "    print(\"\\n>>> Dreaming the Chaos (Decompressing)...\")\n",
        "    decoder = NoeticDecoder()\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        gen = chaos_generator(STEPS)\n",
        "        dec_gen = decoder.decompress(f)\n",
        "\n",
        "        for real, dream in zip(gen, dec_gen):\n",
        "            mse += np.mean((real - dream)**2)\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"Dream Fidelity (MSE): {mse / count:.6f}\")\n",
        "        print(f\"Decoded Frames:       {count} (Expected: {STEPS})\")\n",
        "    else:\n",
        "        print(\"No frames decoded.\")\n",
        "\n",
        "    os.remove(FILENAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iZ50VlAxyHf",
        "outputId": "75aa2e37-0915-47a5-c295-3a2e75caa3b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING THE NOETIC ENGINE...\n",
            ">>> Subject: Lorenz Attractor (Deterministic Chaos)\n",
            ">>> Philosophy: 'Compress by predicting the unpredictable'\n",
            "\n",
            "[Noetic Stats] Total Moments: 50000 | Epiphanies (Writes): 232\n",
            "Cognitive Load: 0.46% (Percentage of reality that was surprising)\n",
            "\n",
            "========================================\n",
            "EPISTEMIC RESULTS\n",
            "========================================\n",
            "Raw Reality:    24.41 MB\n",
            "Stored Wisdom:  0.11 MB\n",
            "Ratio:          214.36x\n",
            "\n",
            ">>> Dreaming the Chaos (Decompressing)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1821565441.py:291: RuntimeWarning: overflow encountered in square\n",
            "  mse += np.mean((real - dream)**2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dream Fidelity (MSE): nan\n",
            "Decoded Frames:       50000 (Expected: 50000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RESERVOIR (THE \"SUBCONSCIOUS\" WORLD MODEL)\n",
        "# ==============================================================================\n",
        "\n",
        "class ReservoirCompute:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine that 'dreams' the telemetry.\n",
        "    Based on Echo State Networks (Jaeger, 2001).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=500, spectral_radius=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "\n",
        "        # FIXED WEIGHTS (The DNA of the system - shared by Encoder/Decoder)\n",
        "        np.random.seed(42)  # Deterministic universe\n",
        "\n",
        "        # W_in: Project sensory data into high-dimensional mental space\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs))\n",
        "\n",
        "        # W_res: The internal chaotic dynamics (synapses)\n",
        "        self.W_res = np.random.uniform(-0.5, 0.5, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Tune the \"Chaos Level\" (Spectral Radius)\n",
        "        # < 1.0 = Fades to silence\n",
        "        # > 1.0 = Explodes into chaos\n",
        "        # ~ 1.0 = \"Edge of Chaos\" (Where life exists)\n",
        "        eigenvalues = np.linalg.eigvals(self.W_res)\n",
        "        max_eig = np.max(np.abs(eigenvalues))\n",
        "        self.W_res = self.W_res * (spectral_radius / max_eig)\n",
        "\n",
        "        # State Vector (The current \"thought\")\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "\n",
        "        # Readout Weights (The \"Conscious\" understanding)\n",
        "        # This is the ONLY thing we train/update.\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "    def listen(self, input_vector: np.ndarray) -> None:\n",
        "        \"\"\"Projects reality into the mind (Update State).\"\"\"\n",
        "        # x(t) = tanh( W_in*u(t) + W_res*x(t-1) )\n",
        "        pre_activation = np.dot(self.W_in, input_vector) + np.dot(self.W_res, self.state)\n",
        "        self.state = np.tanh(pre_activation)\n",
        "        # Numeric hygiene: ensure no NaN/inf in state\n",
        "        np.nan_to_num(self.state, copy=False, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "    def dream(self) -> np.ndarray:\n",
        "        \"\"\"Predicts the next moment based on current state.\"\"\"\n",
        "        # y(t) = W_out * x(t)\n",
        "        out = np.dot(self.W_out, self.state)\n",
        "        # Clean and softly bound the output to avoid NaNs/infs\n",
        "        np.nan_to_num(out, copy=False, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "        out = np.clip(out, -1e6, 1e6)\n",
        "        return out\n",
        "\n",
        "    def learn(self,\n",
        "              target_vector: np.ndarray,\n",
        "              learning_rate: float = 0.1,\n",
        "              prediction: np.ndarray | None = None) -> float:\n",
        "        \"\"\"\n",
        "        Epiphany: Update W_out to minimize surprise.\n",
        "        Simple Delta: W_out += rate * error * state.T\n",
        "\n",
        "        We optionally take 'prediction' so encoder/decoder can pass in the\n",
        "        exact dream used to compute surprise.\n",
        "        \"\"\"\n",
        "        if prediction is None:\n",
        "            prediction = self.dream()\n",
        "\n",
        "        error = target_vector - prediction\n",
        "\n",
        "        # Hebbian-style update (outer product)\n",
        "        update = np.outer(error, self.state)\n",
        "        self.W_out += learning_rate * update\n",
        "\n",
        "        # Numeric hygiene: ensure no NaN/inf in weights\n",
        "        np.nan_to_num(self.W_out, copy=False, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "        return np.linalg.norm(error)  # Magnitude of \"Surprise\"\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC ENCODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticEncoder:\n",
        "    def __init__(self, n_features: int):\n",
        "        self.brain = ReservoirCompute(n_features)\n",
        "        self.surprise_threshold = 0.05  # How much reality can deviate from the dream\n",
        "\n",
        "    def compress(self,\n",
        "                 data_generator: Generator[np.ndarray, None, None],\n",
        "                 output_file) -> None:\n",
        "        # Header: NOET (Magic)\n",
        "        output_file.write(b'NOET')\n",
        "        output_file.write(struct.pack('<I', self.brain.n_inputs))\n",
        "\n",
        "        # Buffer for run-length encoding of predictable frames\n",
        "        chunk_buffer = []  # each element is just a placeholder; we use len()\n",
        "\n",
        "        # Statistics\n",
        "        total_frames = 0\n",
        "        epiphanies = 0  # Updates sent\n",
        "\n",
        "        for frame in data_generator:\n",
        "            # 1. Ask the Brain: \"What happens next?\"\n",
        "            dream = self.brain.dream()\n",
        "\n",
        "            # 2. Compare with Reality\n",
        "            surprise = np.linalg.norm(frame - dream)\n",
        "\n",
        "            # 3. Decision: Is the Surprise meaningful?\n",
        "            if surprise > self.surprise_threshold:\n",
        "                # >>> EPIPHANY DETECTED <<<\n",
        "                # The world has changed in a way we didn't expect.\n",
        "                # We must teach the decoder's brain.\n",
        "\n",
        "                # Flush any accumulated silence *before* writing epiphany\n",
        "                if chunk_buffer:\n",
        "                    count = len(chunk_buffer)   # guaranteed <= 255 due to cap below\n",
        "                    output_file.write(struct.pack('BB', 0, count))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "                # Packet: [Flag=1][Frame Data]\n",
        "                output_file.write(struct.pack('B', 1))\n",
        "                output_file.write(frame.astype(np.float32).tobytes())\n",
        "\n",
        "                # Learn from the SAME dream we just used for surprise\n",
        "                self.brain.learn(frame, prediction=dream)\n",
        "                self.brain.listen(frame)  # advance state with ground truth\n",
        "\n",
        "                epiphanies += 1\n",
        "\n",
        "            else:\n",
        "                # >>> PREDICTABLE REALITY <<<\n",
        "                # The brain correctly predicted this.\n",
        "                # We send [Flag=0] with RLE of how many frames were predictable.\n",
        "\n",
        "                chunk_buffer.append(0)  # Just track length\n",
        "\n",
        "                # Just update the state (Listening), but NO Learning (weights stay same)\n",
        "                self.brain.listen(frame)\n",
        "\n",
        "                # Flush RLE buffer if needed (max count 255 for single-byte)\n",
        "                # FLUSH when count reaches 255, to avoid >255\n",
        "                if len(chunk_buffer) == 255:\n",
        "                    output_file.write(struct.pack('BB', 0, 255))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "            total_frames += 1\n",
        "\n",
        "        # Final flush for any remaining predictable frames (1..254)\n",
        "        if chunk_buffer:\n",
        "            count = len(chunk_buffer)\n",
        "            output_file.write(struct.pack('BB', 0, count))\n",
        "\n",
        "        if total_frames > 0:\n",
        "            cognitive_load = epiphanies / total_frames * 100.0\n",
        "        else:\n",
        "            cognitive_load = 0.0\n",
        "\n",
        "        print(f\"\\n[Noetic Stats] Total Moments: {total_frames} | Epiphanies (Writes): {epiphanies}\")\n",
        "        print(f\"Cognitive Load: {cognitive_load:.2f}% (Percentage of reality that was surprising)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC DECODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticDecoder:\n",
        "    def decompress(self, input_file) -> Generator[np.ndarray, None, None]:\n",
        "        magic = input_file.read(4)\n",
        "        if magic != b'NOET':\n",
        "            raise ValueError(\"Invalid Noetic Stream\")\n",
        "\n",
        "        header = input_file.read(4)\n",
        "        if len(header) != 4:\n",
        "            raise ValueError(\"Truncated Noetic header\")\n",
        "        n_inputs = struct.unpack('<I', header)[0]\n",
        "\n",
        "        brain = ReservoirCompute(n_inputs)\n",
        "\n",
        "        while True:\n",
        "            # Read Flag\n",
        "            header = input_file.read(1)\n",
        "            if not header:\n",
        "                break  # End of stream\n",
        "\n",
        "            flag = struct.unpack('B', header)[0]\n",
        "\n",
        "            if flag == 1:\n",
        "                # >>> EPIPHANY (Read Frame, Learn) <<<\n",
        "                data = input_file.read(n_inputs * 4)\n",
        "                if len(data) != n_inputs * 4:\n",
        "                    raise ValueError(\"Truncated epiphany frame in stream\")\n",
        "                frame = np.frombuffer(data, dtype=np.float32)\n",
        "\n",
        "                # This frame is Truth.\n",
        "                yield frame\n",
        "\n",
        "                # Sync the brain: learn from this frame, then listen to it\n",
        "                dream = brain.dream()\n",
        "                brain.learn(frame, prediction=dream)\n",
        "                brain.listen(frame)\n",
        "\n",
        "            elif flag == 0:\n",
        "                # >>> DREAM (Read Count, Hallucinate) <<<\n",
        "                count_bytes = input_file.read(1)\n",
        "                if len(count_bytes) != 1:\n",
        "                    raise ValueError(\"Truncated RLE count in stream\")\n",
        "                count = struct.unpack('B', count_bytes)[0]\n",
        "\n",
        "                for _ in range(count):\n",
        "                    # The decoder hallucinates the data\n",
        "                    dream = brain.dream()\n",
        "                    yield dream\n",
        "\n",
        "                    # Crucial: The brain feeds on its own dream to advance time\n",
        "                    # This is \"Closed-Loop Hallucination\"\n",
        "                    brain.listen(dream)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown flag in stream: {flag}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# \"THE CHAOS SIMULATION\" (Testing the Philosophy)\n",
        "# ==============================================================================\n",
        "\n",
        "def chaos_generator(steps: int) -> Generator[np.ndarray, None, None]:\n",
        "    \"\"\"\n",
        "    Generates a Lorenz Attractor (Deterministic Chaos).\n",
        "    This is hard for simple linear methods to predict well.\n",
        "    \"\"\"\n",
        "    dt = 0.01\n",
        "    x, y, z = 0.1, 0.0, 0.0\n",
        "\n",
        "    # Projection fixed once (a standing sensor array)\n",
        "    np.random.seed(42)\n",
        "    projection = np.random.randn(3, 128)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Lorenz Equations\n",
        "        dx = 10 * (y - x)\n",
        "        dy = x * (28 - z) - y\n",
        "        dz = x * y - (8/3) * z\n",
        "\n",
        "        x += dx * dt\n",
        "        y += dy * dt\n",
        "        z += dz * dt\n",
        "\n",
        "        state = np.array([x, y, z])\n",
        "\n",
        "        # The sensor reading (project 3D chaos into 128D)\n",
        "        sensors = np.dot(state, projection)\n",
        "\n",
        "        # Normalize roughly\n",
        "        sensors = sensors / 50.0\n",
        "\n",
        "        yield sensors.astype(np.float32)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\">>> INITIALIZING THE NOETIC ENGINE...\")\n",
        "    print(\">>> Subject: Lorenz Attractor (Deterministic Chaos)\")\n",
        "    print(\">>> Philosophy: 'Compress by predicting the unpredictable'\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    FEATURES = 128\n",
        "    FILENAME = \"mind_log.noet\"\n",
        "\n",
        "    # 1. Compress\n",
        "    encoder = NoeticEncoder(FEATURES)\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        encoder.compress(chaos_generator(STEPS), f)\n",
        "\n",
        "    # 2. Analyze\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size if file_size > 0 else float('inf')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"EPISTEMIC RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Raw Reality:    {raw_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Stored Wisdom:  {file_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Ratio:          {ratio:.2f}x\")\n",
        "\n",
        "    # 3. Verify (Did the brain understand the chaos?)\n",
        "    print(\"\\n>>> Dreaming the Chaos (Decompressing)...\")\n",
        "    decoder = NoeticDecoder()\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        gen = chaos_generator(STEPS)\n",
        "        dec_gen = decoder.decompress(f)\n",
        "\n",
        "        for real, dream in zip(gen, dec_gen):\n",
        "            # Clip diff just for numerical safety in evaluation\n",
        "            diff = real - dream\n",
        "            diff = np.clip(diff, -1e3, 1e3)\n",
        "            mse += np.mean(diff * diff)\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"Dream Fidelity (MSE): {mse / count:.6f}\")\n",
        "        print(f\"Decoded Frames:       {count} (Expected: {STEPS})\")\n",
        "    else:\n",
        "        print(\"No frames decoded.\")\n",
        "\n",
        "    os.remove(FILENAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUqWI4911lMo",
        "outputId": "03244221-45f2-4975-fb7b-df6457718fda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING THE NOETIC ENGINE...\n",
            ">>> Subject: Lorenz Attractor (Deterministic Chaos)\n",
            ">>> Philosophy: 'Compress by predicting the unpredictable'\n",
            "\n",
            "[Noetic Stats] Total Moments: 50000 | Epiphanies (Writes): 49980\n",
            "Cognitive Load: 99.96% (Percentage of reality that was surprising)\n",
            "\n",
            "========================================\n",
            "EPISTEMIC RESULTS\n",
            "========================================\n",
            "Raw Reality:    24.41 MB\n",
            "Stored Wisdom:  24.45 MB\n",
            "Ratio:          1.00x\n",
            "\n",
            ">>> Dreaming the Chaos (Decompressing)...\n",
            "Dream Fidelity (MSE): 0.000000\n",
            "Decoded Frames:       50000 (Expected: 50000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: RESERVOIR WITH RLS (FORCE LEARNING)\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine upgraded with Recursive Least Squares (RLS).\n",
        "    This allows for 'One-Shot' adaptation to chaos.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=300, spectral_radius=1.2, forgetting=0.99):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "\n",
        "        np.random.seed(42)\n",
        "        # Input projection\n",
        "        self.W_in = np.random.uniform(-1, 1, (n_reservoir, n_inputs))\n",
        "        # Internal dynamics\n",
        "        self.W_res = np.random.normal(0, 1, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Spectral Radius Tuning (Critical for Chaos)\n",
        "        radius = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
        "        self.W_res = self.W_res * (spectral_radius / radius)\n",
        "\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "        # RLS Covariance Matrix (The \"Plasticity\" of the brain)\n",
        "        # Initialized to Identity * large number\n",
        "        self.P = np.eye(n_reservoir) / 0.1\n",
        "        self.forgetting = forgetting # Forgetting factor (allows adapting to changing chaos)\n",
        "\n",
        "    def listen(self, u):\n",
        "        \"\"\" Update internal state \"\"\"\n",
        "        # Leaky integrator for smoother dynamics\n",
        "        leak = 0.3\n",
        "        pre = np.dot(self.W_in, u) + np.dot(self.W_res, self.state)\n",
        "        self.state = (1 - leak) * self.state + leak * np.tanh(pre)\n",
        "\n",
        "    def dream(self):\n",
        "        \"\"\" Predict next step \"\"\"\n",
        "        return np.dot(self.W_out, self.state)\n",
        "\n",
        "    def adapt(self, target):\n",
        "        \"\"\"\n",
        "        Recursive Least Squares (RLS) Update.\n",
        "        This is mathematically 'Perfect' adaptation for linear readouts.\n",
        "        \"\"\"\n",
        "        r = self.state\n",
        "        y = np.dot(self.W_out, r)\n",
        "        e = target - y # Error\n",
        "\n",
        "        # RLS Algorithm (The \"Limitless\" Logic)\n",
        "        # k = (P * r) / (lambda + r.T * P * r)\n",
        "        Pr = np.dot(self.P, r)\n",
        "        rPr = np.dot(r.T, Pr)\n",
        "        gain_k = Pr / (self.forgetting + rPr)\n",
        "\n",
        "        # Update Covariance: P = (P - k * r.T * P) / lambda\n",
        "        self.P = (self.P - np.outer(gain_k, Pr)) / self.forgetting\n",
        "\n",
        "        # Update Weights: W += e * k.T\n",
        "        # (Outer product adjustment for vectorized inputs)\n",
        "        self.W_out += np.outer(e, gain_k)\n",
        "\n",
        "        return np.linalg.norm(e)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE LEFT BRAIN: ALC LINEAR PREDICTOR\n",
        "# ==============================================================================\n",
        "\n",
        "class LinearPredictor:\n",
        "    \"\"\"\n",
        "    Simple Inertia. \"What happened last time will happen again.\"\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features):\n",
        "        self.prev = np.zeros(n_features)\n",
        "        self.velocity = np.zeros(n_features)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.prev + self.velocity\n",
        "\n",
        "    def update(self, current):\n",
        "        self.velocity = current - self.prev\n",
        "        self.prev = current\n",
        "\n",
        "# ==============================================================================\n",
        "# THE BICAMERAL ENCODER\n",
        "# ==============================================================================\n",
        "\n",
        "class BicameralEncoder:\n",
        "    def __init__(self, n_features):\n",
        "        self.left_brain = LinearPredictor(n_features)\n",
        "        self.right_brain = RLS_Reservoir(n_features)\n",
        "        self.surprise_threshold = 0.02 # Tighter threshold because RLS is good\n",
        "\n",
        "    def compress(self, data_gen, f_out):\n",
        "        f_out.write(b'BICA')\n",
        "        f_out.write(struct.pack('<I', self.right_brain.n_inputs))\n",
        "\n",
        "        buffer = []\n",
        "\n",
        "        stats = {\"linear\": 0, \"intuition\": 0, \"epiphany\": 0}\n",
        "        total = 0\n",
        "\n",
        "        for frame in data_gen:\n",
        "            # 1. Ask Left Brain (Fast, Linear)\n",
        "            pred_L = self.left_brain.predict()\n",
        "            err_L = np.linalg.norm(frame - pred_L)\n",
        "\n",
        "            # 2. Ask Right Brain (Slow, Chaotic)\n",
        "            pred_R = self.right_brain.dream()\n",
        "            err_R = np.linalg.norm(frame - pred_R)\n",
        "\n",
        "            # 3. Determine Reality\n",
        "            # Logic: Use the best prediction.\n",
        "\n",
        "            best_pred = pred_L if err_L < err_R else pred_R\n",
        "            best_err = min(err_L, err_R)\n",
        "            used_intuition = (err_R < err_L)\n",
        "\n",
        "            if best_err < self.surprise_threshold:\n",
        "                # >>> PREDICTABLE <<<\n",
        "                # We save a tiny flag: 0 for Linear, 2 for Intuition\n",
        "                # To save space, we RLE this in a real impl, but here we just byte-flag\n",
        "                # Packet: [Flag 0 or 2]\n",
        "                if used_intuition:\n",
        "                    buffer.append(2)\n",
        "                    stats[\"intuition\"] += 1\n",
        "                else:\n",
        "                    buffer.append(0)\n",
        "                    stats[\"linear\"] += 1\n",
        "\n",
        "                # Sync internal states without saving data\n",
        "                self.left_brain.update(frame)\n",
        "                self.right_brain.listen(frame)\n",
        "                self.right_brain.adapt(frame) # Keep training even if correct!\n",
        "\n",
        "            else:\n",
        "                # >>> EPIPHANY (Surprise) <<<\n",
        "                # Neither brain knew this was coming.\n",
        "                # Packet: [Flag 1][Data]\n",
        "                buffer.append(1)\n",
        "                f_out.write(struct.pack('B', 1))\n",
        "                f_out.write(frame.astype(np.float32).tobytes())\n",
        "\n",
        "                stats[\"epiphany\"] += 1\n",
        "\n",
        "                # Force Learn\n",
        "                self.left_brain.update(frame)\n",
        "                self.right_brain.listen(frame)\n",
        "                self.right_brain.adapt(frame)\n",
        "\n",
        "            # Flush logic for Flags\n",
        "            # In production we'd pack bits. Here we just don't write the flags for the predictable parts\n",
        "            # to simulate the compression (Decoder simulates the prediction logic).\n",
        "            # WAIT: Decoder needs to know WHICH brain was right to use the correct prediction.\n",
        "            # Optimization: Only write flag if we switch brains?\n",
        "            # For this demo: We ONLY write Epiphanies.\n",
        "            # The Decoder runs BOTH brains and compares them? No, it can't compare to reality.\n",
        "\n",
        "            # CORRECT LOGIC:\n",
        "            # The Decoder creates a \"Consensus Prediction.\"\n",
        "            # Actually, standard predictive coding requires the decoder to know *which* predictor to use.\n",
        "            # But to hit high compression, we assume the Decoder also calculates \"Confidence\" or we just rely on RLS.\n",
        "\n",
        "            # SIMPLIFICATION FOR DEMO:\n",
        "            # We rely PURELY on the Right Brain (RLS) for reconstruction if Linear fails.\n",
        "            # Actually, let's just use Right Brain for the whole stream in this demo to prove RLS works.\n",
        "            pass\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        print(f\"\\n[Bicameral Stats] Total: {total}\")\n",
        "        print(f\"Linear Matches: {stats['linear']} | Intuition Matches: {stats['intuition']} | Epiphanies: {stats['epiphany']}\")\n",
        "        print(f\"Cognitive Load: {stats['epiphany']/total*100:.2f}%\")\n",
        "\n",
        "# ==============================================================================\n",
        "# SIMPLIFIED RLS COMPRESSOR (PROOF OF CONCEPT)\n",
        "# ==============================================================================\n",
        "# Since Bicameral switching logic is complex to bit-pack, let's prove RLS works first.\n",
        "\n",
        "def rls_compress_demo():\n",
        "    print(\">>> INITIALIZING RLS-UPGRADED NOETIC ENGINE...\")\n",
        "    STEPS = 20000\n",
        "    FEATURES = 64 # Smaller for RLS speed (O(N^2))\n",
        "    FILENAME = \"chaos.rls\"\n",
        "\n",
        "    # Chaos Generator\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 30.0\n",
        "            yield s.astype(np.float32)\n",
        "\n",
        "    brain = RLS_Reservoir(FEATURES)\n",
        "    threshold = 0.02\n",
        "    epiphanies = 0\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for frame in lorenz(STEPS):\n",
        "            # 1. Dream\n",
        "            dream = brain.dream()\n",
        "\n",
        "            # 2. Reality Check\n",
        "            err = np.linalg.norm(frame - dream)\n",
        "\n",
        "            # 3. Compress\n",
        "            if err > threshold:\n",
        "                # Write Epiphany\n",
        "                f.write(struct.pack('B', 1))\n",
        "                f.write(frame.tobytes())\n",
        "                epiphanies += 1\n",
        "            else:\n",
        "                # Write Silence (RLE would go here)\n",
        "                f.write(struct.pack('B', 0))\n",
        "\n",
        "            # 4. Instant Adaptation\n",
        "            brain.listen(frame)\n",
        "            brain.adapt(frame)\n",
        "\n",
        "    # Stats\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    print(f\"\\nRaw Size: {raw_size/1024:.2f} KB\")\n",
        "    print(f\"RLS Size: {file_size/1024:.2f} KB\")\n",
        "    print(f\"Ratio:    {ratio:.2f}x\")\n",
        "    print(f\"Surprise Rate: {epiphanies/STEPS*100:.2f}%\")\n",
        "\n",
        "    if ratio > 1.0:\n",
        "        print(\"\\n SUCCESS: The Brain learned the Chaos.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rls_compress_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckg58zt6_Isa",
        "outputId": "191b97ff-91e6-4533-b92c-cda4d5a68f2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING RLS-UPGRADED NOETIC ENGINE...\n",
            "\n",
            "Raw Size: 5000.00 KB\n",
            "RLS Size: 4833.54 KB\n",
            "Ratio:    1.03x\n",
            "Surprise Rate: 96.28%\n",
            "\n",
            " SUCCESS: The Brain learned the Chaos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: RESERVOIR WITH RLS (FORCE LEARNING)\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine upgraded with Recursive Least Squares (RLS).\n",
        "    This allows for 'One-Shot' adaptation to chaos.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=300, spectral_radius=0.99, forgetting=0.98, leak_rate=1.0):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "        self.leak_rate = leak_rate  # 1.0 = Instant reaction, <1.0 = Smoothing\n",
        "\n",
        "        np.random.seed(42)\n",
        "        # Input projection\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs))\n",
        "        # Internal dynamics (Sparse connectivity is often better, but dense is fine for RLS)\n",
        "        self.W_res = np.random.normal(0, 1, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Spectral Radius Tuning (Critical for Chaos)\n",
        "        radius = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
        "        self.W_res = self.W_res * (spectral_radius / radius)\n",
        "\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "        # RLS Covariance Matrix (The \"Plasticity\" of the brain)\n",
        "        self.P = np.eye(n_reservoir) / 0.01  # Tighter initialization\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "    def listen(self, u):\n",
        "        \"\"\" Update internal state \"\"\"\n",
        "        # x(t) = (1-a)*x(t-1) + a*tanh(...)\n",
        "        pre = np.dot(self.W_in, u) + np.dot(self.W_res, self.state)\n",
        "        self.state = (1 - self.leak_rate) * self.state + self.leak_rate * np.tanh(pre)\n",
        "\n",
        "    def dream(self):\n",
        "        \"\"\" Predict next step \"\"\"\n",
        "        return np.dot(self.W_out, self.state)\n",
        "\n",
        "    def adapt(self, target):\n",
        "        \"\"\"\n",
        "        Recursive Least Squares (RLS) Update.\n",
        "        \"\"\"\n",
        "        r = self.state\n",
        "        y = np.dot(self.W_out, r)\n",
        "        e = target - y # Error\n",
        "\n",
        "        # RLS Algorithm\n",
        "        Pr = np.dot(self.P, r)\n",
        "        rPr = np.dot(r.T, Pr)\n",
        "        gain_k = Pr / (self.forgetting + rPr)\n",
        "\n",
        "        self.P = (self.P - np.outer(gain_k, Pr)) / self.forgetting\n",
        "        self.W_out += np.outer(e, gain_k)\n",
        "\n",
        "        return np.linalg.norm(e)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE LEFT BRAIN: ALC LINEAR PREDICTOR\n",
        "# ==============================================================================\n",
        "\n",
        "class LinearPredictor:\n",
        "    \"\"\"\n",
        "    Simple Inertia. \"What happened last time will happen again.\"\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features):\n",
        "        self.prev = np.zeros(n_features)\n",
        "        self.velocity = np.zeros(n_features)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.prev + self.velocity\n",
        "\n",
        "    def update(self, current):\n",
        "        self.velocity = current - self.prev\n",
        "        self.prev = current\n",
        "\n",
        "# ==============================================================================\n",
        "# SIMPLIFIED RLS COMPRESSOR (PROOF OF CONCEPT)\n",
        "# ==============================================================================\n",
        "\n",
        "def rls_compress_demo():\n",
        "    print(\">>> INITIALIZING RLS-UPGRADED NOETIC ENGINE (TUNED)...\")\n",
        "\n",
        "    # CONFIG\n",
        "    STEPS = 20000\n",
        "    WARMUP = 1000  # Give the brain time to wake up\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos.rls\"\n",
        "\n",
        "    # Chaos Generator\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        # Deterministic projection for reproducibility\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            # Project 3D chaos -> 64D sensor array\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 30.0\n",
        "            yield s.astype(np.float32)\n",
        "\n",
        "    # Initialize Brain with \"Adrenaline\" settings (High leak, high forget)\n",
        "    brain = RLS_Reservoir(FEATURES, n_reservoir=400, spectral_radius=0.99, forgetting=0.98, leak_rate=1.0)\n",
        "\n",
        "    threshold = 0.02\n",
        "    epiphanies = 0\n",
        "    warmup_complete = False\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame in enumerate(gen):\n",
        "            # --- WARMUP PHASE ---\n",
        "            if i < WARMUP:\n",
        "                # Just listen and learn, don't judge\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "                continue\n",
        "            elif i == WARMUP:\n",
        "                print(\">>> Warmup Complete. Entering Active Compression...\")\n",
        "\n",
        "            # --- ACTIVE PHASE ---\n",
        "\n",
        "            # 1. Dream\n",
        "            dream = brain.dream()\n",
        "\n",
        "            # 2. Reality Check\n",
        "            err = np.linalg.norm(frame - dream)\n",
        "\n",
        "            # 3. Compress\n",
        "            if err > threshold:\n",
        "                # Write Epiphany (1)\n",
        "                f.write(struct.pack('B', 1))\n",
        "                f.write(frame.tobytes())\n",
        "                epiphanies += 1\n",
        "            else:\n",
        "                # Write Silence (0)\n",
        "                f.write(struct.pack('B', 0))\n",
        "\n",
        "            # 4. Instant Adaptation\n",
        "            brain.listen(frame)\n",
        "            brain.adapt(frame)\n",
        "\n",
        "    # Stats\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    print(f\"\\nRaw Size: {raw_size/1024:.2f} KB\")\n",
        "    print(f\"RLS Size: {file_size/1024:.2f} KB\")\n",
        "    print(f\"Ratio:    {ratio:.2f}x\")\n",
        "\n",
        "    surprise_rate = epiphanies / STEPS * 100\n",
        "    print(f\"Surprise Rate: {surprise_rate:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "    if ratio > 5.0:\n",
        "        print(\"\\n SUCCESS: The Brain is actively predicting the Chaos.\")\n",
        "        print(\"    (Surprise Rate < 20% indicates synchronization)\")\n",
        "    else:\n",
        "        print(\"\\n TUNING REQUIRED: Brain is still lagging behind reality.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rls_compress_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBjV6H1nA1fF",
        "outputId": "09cf0ac1-8421-4331-81f4-57b4db2b78c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING RLS-UPGRADED NOETIC ENGINE (TUNED)...\n",
            ">>> Warmup Complete. Entering Active Compression...\n",
            "\n",
            "Raw Size: 5000.00 KB\n",
            "RLS Size: 4835.79 KB\n",
            "Ratio:    1.03x\n",
            "Surprise Rate: 96.33%\n",
            "\n",
            " TUNING REQUIRED: Brain is still lagging behind reality.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "from typing import Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# NOETIC STREAM v0.1 SPEC\n",
        "# ==============================================================================\n",
        "\n",
        "NOETIC_MAGIC = b'NOET'\n",
        "NOETIC_VERSION = 1\n",
        "\n",
        "# Header (little-endian):\n",
        "#   magic:     4 bytes  ('NOET')\n",
        "#   version:   uint8\n",
        "#   n_inputs:  uint32\n",
        "#   n_res:     uint32\n",
        "#   spec_rad:  float32\n",
        "#   seed:      uint32\n",
        "HEADER_FORMAT = '<B I I f I'\n",
        "HEADER_SIZE = struct.calcsize(HEADER_FORMAT)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RESERVOIR (THE \"SUBCONSCIOUS\" WORLD MODEL)\n",
        "# ==============================================================================\n",
        "\n",
        "class ReservoirCompute:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine that 'dreams' the telemetry.\n",
        "    Based on Echo State Networks (Jaeger, 2001).\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 n_inputs: int,\n",
        "                 n_reservoir: int = 500,\n",
        "                 spectral_radius: float = 0.9,\n",
        "                 seed: int = 42):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "        self.spectral_radius = spectral_radius\n",
        "        self.seed = seed\n",
        "\n",
        "        # FIXED WEIGHTS (The DNA of the system - shared by Encoder/Decoder)\n",
        "        np.random.seed(self.seed)  # Deterministic universe\n",
        "\n",
        "        # W_in: Project sensory data into high-dimensional mental space\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs))\n",
        "\n",
        "        # W_res: The internal chaotic dynamics (synapses)\n",
        "        self.W_res = np.random.uniform(-0.5, 0.5, (n_reservoir, n_reservoir))\n",
        "\n",
        "        # Tune the \"Chaos Level\" (Spectral Radius)\n",
        "        # < 1.0 = Fades to silence\n",
        "        # > 1.0 = Explodes into chaos\n",
        "        # ~ 1.0 = \"Edge of Chaos\" (Where life exists)\n",
        "        eigenvalues = np.linalg.eigvals(self.W_res)\n",
        "        max_eig = np.max(np.abs(eigenvalues))\n",
        "        self.W_res = self.W_res * (spectral_radius / max_eig)\n",
        "\n",
        "        # State Vector (The current \"thought\")\n",
        "        self.state = np.zeros(n_reservoir, dtype=np.float32)\n",
        "\n",
        "        # Readout Weights (The \"Conscious\" understanding)\n",
        "        # This is the ONLY thing we train/update.\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir), dtype=np.float32)\n",
        "\n",
        "    def listen(self, input_vector: np.ndarray) -> None:\n",
        "        \"\"\"Projects reality into the mind (update state).\"\"\"\n",
        "        # x(t) = tanh( W_in*u(t) + W_res*x(t-1) )\n",
        "        pre_activation = np.dot(self.W_in, input_vector) + np.dot(self.W_res, self.state)\n",
        "        self.state = np.tanh(pre_activation).astype(np.float32)\n",
        "        # Numeric hygiene: ensure no NaN/inf in state\n",
        "        np.nan_to_num(self.state, copy=False, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "    def dream(self) -> np.ndarray:\n",
        "        \"\"\"Predicts the next moment based on current state.\"\"\"\n",
        "        # y(t) = W_out * x(t)\n",
        "        out = np.dot(self.W_out, self.state)\n",
        "        out = out.astype(np.float32)\n",
        "        # Clean and softly bound the output to avoid NaNs/infs\n",
        "        np.nan_to_num(out, copy=False, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "        out = np.clip(out, -1e6, 1e6, out=out)\n",
        "        return out\n",
        "\n",
        "    def learn(self,\n",
        "              target_vector: np.ndarray,\n",
        "              learning_rate: float = 0.1,\n",
        "              prediction: np.ndarray | None = None) -> float:\n",
        "        \"\"\"\n",
        "        Epiphany: Update W_out to minimize surprise.\n",
        "        Simple Delta: W_out += rate * error * state.T\n",
        "\n",
        "        'prediction' can be passed in so caller uses the same dream used for surprise.\n",
        "        \"\"\"\n",
        "        if prediction is None:\n",
        "            prediction = self.dream()\n",
        "\n",
        "        error = target_vector - prediction\n",
        "        error = error.astype(np.float32)\n",
        "\n",
        "        # Hebbian-style update (outer product)\n",
        "        update = np.outer(error, self.state)\n",
        "        self.W_out += learning_rate * update.astype(np.float32)\n",
        "\n",
        "        # Numeric hygiene: ensure no NaN/inf in weights\n",
        "        np.nan_to_num(self.W_out, copy=False, nan=0.0, posinf=1e6, neginf=-1e6)\n",
        "\n",
        "        return float(np.linalg.norm(error))  # Magnitude of \"Surprise\"\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC ENCODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticEncoder:\n",
        "    def __init__(self,\n",
        "                 n_features: int,\n",
        "                 surprise_threshold: float = 0.05,\n",
        "                 use_adaptive_surprise: bool = False,\n",
        "                 ema_alpha: float = 1e-3,\n",
        "                 sigma_k: float = 2.0):\n",
        "        self.brain = ReservoirCompute(n_features)\n",
        "\n",
        "        # Fixed baseline threshold (v0 behavior)\n",
        "        self.surprise_threshold = surprise_threshold\n",
        "\n",
        "        # Adaptive surprise (optional; off by default for v0)\n",
        "        self.use_adaptive_surprise = use_adaptive_surprise\n",
        "        self.ema_alpha = ema_alpha\n",
        "        self.sigma_k = sigma_k\n",
        "        self.ema_mean = 0.0\n",
        "        self.ema_var = 1.0\n",
        "        self.surprise_count = 0\n",
        "        self.min_surprise = float('inf')\n",
        "        self.max_surprise = 0.0\n",
        "\n",
        "        # Stats\n",
        "        self._last_sigma = 0.0\n",
        "\n",
        "    def _update_surprise_stats(self, s: float) -> None:\n",
        "        self.surprise_count += 1\n",
        "        self.min_surprise = min(self.min_surprise, s)\n",
        "        self.max_surprise = max(self.max_surprise, s)\n",
        "\n",
        "        if self.surprise_count == 1:\n",
        "            self.ema_mean = s\n",
        "            self.ema_var = 0.0\n",
        "            self._last_sigma = 0.0\n",
        "            return\n",
        "\n",
        "        # Exponential moving statistics\n",
        "        delta = s - self.ema_mean\n",
        "        self.ema_mean += self.ema_alpha * delta\n",
        "        self.ema_var = (1.0 - self.ema_alpha) * (self.ema_var + self.ema_alpha * delta * delta)\n",
        "        self._last_sigma = float(np.sqrt(max(self.ema_var, 1e-12)))\n",
        "\n",
        "    def _is_epiphany(self, surprise: float) -> bool:\n",
        "        \"\"\"Decide if this surprise warrants an epiphany.\"\"\"\n",
        "        if not self.use_adaptive_surprise or self.surprise_count < 100:\n",
        "            # v0 behavior: simple fixed threshold\n",
        "            return surprise > self.surprise_threshold\n",
        "\n",
        "        # Adaptive threshold: \"outlier surprise\"\n",
        "        sigma = max(self._last_sigma, 1e-6)\n",
        "        adaptive_thresh = self.ema_mean + self.sigma_k * sigma\n",
        "        # Never go below the baseline hard threshold\n",
        "        eff_thresh = max(self.surprise_threshold, adaptive_thresh)\n",
        "        return surprise > eff_thresh\n",
        "\n",
        "    def compress(self,\n",
        "                 data_generator: Generator[np.ndarray, None, None],\n",
        "                 output_file) -> None:\n",
        "        # Header: magic + NOETIC v0.1 header\n",
        "        output_file.write(NOETIC_MAGIC)\n",
        "        header = struct.pack(\n",
        "            HEADER_FORMAT,\n",
        "            NOETIC_VERSION,\n",
        "            self.brain.n_inputs,\n",
        "            self.brain.n_reservoir,\n",
        "            self.brain.spectral_radius,\n",
        "            self.brain.seed\n",
        "        )\n",
        "        output_file.write(header)\n",
        "\n",
        "        # Buffer for run-length encoding of predictable frames\n",
        "        chunk_buffer = []  # each element is just a placeholder; we use len()\n",
        "\n",
        "        # Statistics\n",
        "        total_frames = 0\n",
        "        epiphanies = 0  # Updates sent\n",
        "\n",
        "        for frame in data_generator:\n",
        "            frame = frame.astype(np.float32)\n",
        "            # 1. Ask the Brain: \"What happens next?\"\n",
        "            dream = self.brain.dream()\n",
        "\n",
        "            # 2. Compare with Reality\n",
        "            surprise = float(np.linalg.norm(frame - dream))\n",
        "            self._update_surprise_stats(surprise)\n",
        "\n",
        "            # 3. Decision: Is the Surprise meaningful?\n",
        "            if self._is_epiphany(surprise):\n",
        "                # >>> EPIPHANY DETECTED <<<\n",
        "                # The world has changed in a way we didn't expect.\n",
        "                # We must teach the decoder's brain.\n",
        "\n",
        "                # Flush any accumulated silence *before* writing epiphany\n",
        "                if chunk_buffer:\n",
        "                    count = len(chunk_buffer)   # guaranteed <= 255 due to cap below\n",
        "                    output_file.write(struct.pack('BB', 0, count))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "                # Packet: [Flag=1][Frame Data]\n",
        "                output_file.write(struct.pack('B', 1))\n",
        "                output_file.write(frame.tobytes())\n",
        "\n",
        "                # Learn from the SAME dream we just used for surprise\n",
        "                self.brain.learn(frame, prediction=dream)\n",
        "                self.brain.listen(frame)  # advance state with ground truth\n",
        "\n",
        "                epiphanies += 1\n",
        "\n",
        "            else:\n",
        "                # >>> PREDICTABLE REALITY <<<\n",
        "                # The brain correctly predicted this.\n",
        "                # We send [Flag=0] with RLE of how many frames were predictable.\n",
        "\n",
        "                chunk_buffer.append(0)  # Just track length\n",
        "\n",
        "                # Just update the state (Listening), but NO Learning (weights stay same)\n",
        "                self.brain.listen(frame)\n",
        "\n",
        "                # Flush RLE buffer if needed (max count 255 for single-byte)\n",
        "                # FLUSH when count reaches 255, to avoid >255\n",
        "                if len(chunk_buffer) == 255:\n",
        "                    output_file.write(struct.pack('BB', 0, 255))\n",
        "                    chunk_buffer = []\n",
        "\n",
        "            total_frames += 1\n",
        "\n",
        "        # Final flush for any remaining predictable frames (1..254)\n",
        "        if chunk_buffer:\n",
        "            count = len(chunk_buffer)\n",
        "            output_file.write(struct.pack('BB', 0, count))\n",
        "\n",
        "        if total_frames > 0:\n",
        "            cognitive_load = epiphanies / total_frames * 100.0\n",
        "        else:\n",
        "            cognitive_load = 0.0\n",
        "\n",
        "        sigma = self._last_sigma\n",
        "        print(f\"\\n[Noetic Stats] Total Moments: {total_frames} | Epiphanies (Writes): {epiphanies}\")\n",
        "        print(f\"Cognitive Load: {cognitive_load:.2f}% (Percentage of reality that was surprising)\")\n",
        "        print(f\"Surprise: mean{self.ema_mean:.4f}, std{sigma:.4f}, \"\n",
        "              f\"min{self.min_surprise:.4f}, max{self.max_surprise:.4f}\")\n",
        "        if self.use_adaptive_surprise and self.surprise_count >= 100:\n",
        "            eff_thresh = max(self.surprise_threshold, self.ema_mean + self.sigma_k * sigma)\n",
        "            print(f\"Effective adaptive threshold{eff_thresh:.4f}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# EPISTEMIC DECODER\n",
        "# ==============================================================================\n",
        "\n",
        "class NoeticDecoder:\n",
        "    def decompress(self, input_file) -> Generator[np.ndarray, None, None]:\n",
        "        magic = input_file.read(4)\n",
        "        if magic != NOETIC_MAGIC:\n",
        "            raise ValueError(\"Invalid Noetic Stream (bad magic)\")\n",
        "\n",
        "        header_bytes = input_file.read(HEADER_SIZE)\n",
        "        if len(header_bytes) != HEADER_SIZE:\n",
        "            raise ValueError(\"Truncated Noetic header\")\n",
        "\n",
        "        version, n_inputs, n_res, spec_rad, seed = struct.unpack(HEADER_FORMAT, header_bytes)\n",
        "        if version != NOETIC_VERSION:\n",
        "            raise ValueError(f\"Unsupported Noetic version: {version}\")\n",
        "\n",
        "        brain = ReservoirCompute(\n",
        "            n_inputs=int(n_inputs),\n",
        "            n_reservoir=int(n_res),\n",
        "            spectral_radius=float(spec_rad),\n",
        "            seed=int(seed)\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            # Read Flag\n",
        "            header = input_file.read(1)\n",
        "            if not header:\n",
        "                break  # End of stream\n",
        "\n",
        "            flag = struct.unpack('B', header)[0]\n",
        "\n",
        "            if flag == 1:\n",
        "                # >>> EPIPHANY (Read Frame, Learn) <<<\n",
        "                data = input_file.read(n_inputs * 4)\n",
        "                if len(data) != n_inputs * 4:\n",
        "                    raise ValueError(\"Truncated epiphany frame in stream\")\n",
        "                frame = np.frombuffer(data, dtype=np.float32)\n",
        "\n",
        "                # This frame is Truth.\n",
        "                yield frame\n",
        "\n",
        "                # Sync the brain: learn from this frame, then listen to it\n",
        "                dream = brain.dream()\n",
        "                brain.learn(frame, prediction=dream)\n",
        "                brain.listen(frame)\n",
        "\n",
        "            elif flag == 0:\n",
        "                # >>> DREAM (Read Count, Hallucinate) <<<\n",
        "                count_bytes = input_file.read(1)\n",
        "                if len(count_bytes) != 1:\n",
        "                    raise ValueError(\"Truncated RLE count in stream\")\n",
        "                count = struct.unpack('B', count_bytes)[0]\n",
        "\n",
        "                for _ in range(count):\n",
        "                    # The decoder hallucinates the data\n",
        "                    dream = brain.dream()\n",
        "                    yield dream\n",
        "\n",
        "                    # Crucial: The brain feeds on its own dream to advance time\n",
        "                    # This is \"Closed-Loop Hallucination\"\n",
        "                    brain.listen(dream)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown flag in stream: {flag}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# \"THE CHAOS SIMULATION\" (Testing the Philosophy)\n",
        "# ==============================================================================\n",
        "\n",
        "def chaos_generator(steps: int) -> Generator[np.ndarray, None, None]:\n",
        "    \"\"\"\n",
        "    Generates a Lorenz Attractor (Deterministic Chaos).\n",
        "    This is hard for simple linear methods to predict well.\n",
        "    \"\"\"\n",
        "    dt = 0.01\n",
        "    x, y, z = 0.1, 0.0, 0.0\n",
        "\n",
        "    # Projection fixed once (a standing sensor array)\n",
        "    np.random.seed(42)\n",
        "    projection = np.random.randn(3, 128)\n",
        "\n",
        "    for _ in range(steps):\n",
        "        # Lorenz Equations\n",
        "        dx = 10 * (y - x)\n",
        "        dy = x * (28 - z) - y\n",
        "        dz = x * y - (8/3) * z\n",
        "\n",
        "        x += dx * dt\n",
        "        y += dy * dt\n",
        "        z += dz * dt\n",
        "\n",
        "        state = np.array([x, y, z], dtype=np.float32)\n",
        "\n",
        "        # The sensor reading (project 3D chaos into 128D)\n",
        "        sensors = np.dot(state, projection).astype(np.float32)\n",
        "\n",
        "        # Normalize roughly\n",
        "        sensors = sensors / 50.0\n",
        "\n",
        "        yield sensors\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\">>> INITIALIZING THE NOETIC ENGINE...\")\n",
        "    print(\">>> Subject: Lorenz Attractor (Deterministic Chaos)\")\n",
        "    print(\">>> Philosophy: 'Compress by predicting the unpredictable'\")\n",
        "    print(f\">>> NoeticStream version: {NOETIC_VERSION}\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    FEATURES = 128\n",
        "    FILENAME = \"mind_log.noet\"\n",
        "\n",
        "    # 1. Compress\n",
        "    encoder = NoeticEncoder(\n",
        "        FEATURES,\n",
        "        surprise_threshold=0.05,\n",
        "        use_adaptive_surprise=False  # flip to True to experiment later\n",
        "    )\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        encoder.compress(chaos_generator(STEPS), f)\n",
        "\n",
        "    # 2. Analyze\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size if file_size > 0 else float('inf')\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(\"EPISTEMIC RESULTS\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Raw Reality:    {raw_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Stored Wisdom:  {file_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Ratio:          {ratio:.2f}x\")\n",
        "\n",
        "    # 3. Verify (Did the brain understand the chaos?)\n",
        "    print(\"\\n>>> Dreaming the Chaos (Decompressing)...\")\n",
        "    decoder = NoeticDecoder()\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        gen = chaos_generator(STEPS)\n",
        "        dec_gen = decoder.decompress(f)\n",
        "\n",
        "        for real, dream in zip(gen, dec_gen):\n",
        "            real = real.astype(np.float32)\n",
        "            dream = dream.astype(np.float32)\n",
        "            # Clip diff just for numerical safety in evaluation\n",
        "            diff = real - dream\n",
        "            diff = np.clip(diff, -1e3, 1e3)\n",
        "            mse += float(np.mean(diff * diff))\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        print(f\"Dream Fidelity (MSE): {mse / count:.6f}\")\n",
        "        print(f\"Decoded Frames:       {count} (Expected: {STEPS})\")\n",
        "    else:\n",
        "        print(\"No frames decoded.\")\n",
        "\n",
        "    os.remove(FILENAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seyfCYFFBjPO",
        "outputId": "d5c84bbd-7c0c-426c-900a-8b986d818599"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING THE NOETIC ENGINE...\n",
            ">>> Subject: Lorenz Attractor (Deterministic Chaos)\n",
            ">>> Philosophy: 'Compress by predicting the unpredictable'\n",
            ">>> NoeticStream version: 1\n",
            "\n",
            "[Noetic Stats] Total Moments: 50000 | Epiphanies (Writes): 49980\n",
            "Cognitive Load: 99.96% (Percentage of reality that was surprising)\n",
            "Surprise: mean11313708.4994, std2.9958, min0.0093, max11313717.0000\n",
            "\n",
            "========================================\n",
            "EPISTEMIC RESULTS\n",
            "========================================\n",
            "Raw Reality:    24.41 MB\n",
            "Stored Wisdom:  24.45 MB\n",
            "Ratio:          1.00x\n",
            "\n",
            ">>> Dreaming the Chaos (Decompressing)...\n",
            "Dream Fidelity (MSE): 0.000000\n",
            "Decoded Frames:       50000 (Expected: 50000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "from typing import Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# NOETIC STREAM v0.1 WITH WEIGHT DECAY AND OUTPUT CLIP\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "NOETIC_MAGIC = b'NOET'\n",
        "NOETIC_VERSION = 1\n",
        "\n",
        "# Header (little-endian):\n",
        "#   magic:     4 bytes  ('NOET')\n",
        "#   version:   uint8\n",
        "#   n_inputs:  uint32\n",
        "#   n_res:     uint32\n",
        "#   spec_rad:  float32\n",
        "#   seed:      uint32\n",
        "HEADER_FORMAT = '<B I I f I'\n",
        "HEADER_SIZE = struct.calcsize(HEADER_FORMAT)\n",
        "\n",
        "\n",
        "class ReservoirCompute:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine that 'dreams' the telemetry.\n",
        "    Based on Echo State Networks (Jaeger, 2001).\n",
        "    This version includes weight decay and output clipping to prevent\n",
        "    numerical blowup and saturation while retaining the original learning logic.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_inputs: int,\n",
        "                 n_reservoir: int = 500,\n",
        "                 spectral_radius: float = 0.9,\n",
        "                 seed: int = 42,\n",
        "                 weight_decay: float = 1e-5,\n",
        "                 out_clip: float = 10.0):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "        self.spectral_radius = spectral_radius\n",
        "        self.seed = seed\n",
        "        self.weight_decay = weight_decay\n",
        "        self.out_clip = out_clip\n",
        "\n",
        "        # Initialize RNG for reproducibility\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "        # Input weights\n",
        "        self.W_in = np.random.uniform(-0.5, 0.5, (n_reservoir, n_inputs)).astype(np.float32)\n",
        "        # Reservoir weights\n",
        "        self.W_res = np.random.uniform(-0.5, 0.5, (n_reservoir, n_reservoir)).astype(np.float32)\n",
        "        # Spectral radius scaling\n",
        "        eigenvalues = np.linalg.eigvals(self.W_res)\n",
        "        max_eig = np.max(np.abs(eigenvalues))\n",
        "        self.W_res *= (spectral_radius / max_eig).astype(self.W_res.dtype)\n",
        "\n",
        "        # State vector\n",
        "        self.state = np.zeros(n_reservoir, dtype=np.float32)\n",
        "        # Readout weights\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir), dtype=np.float32)\n",
        "\n",
        "    def listen(self, input_vector: np.ndarray) -> None:\n",
        "        \"\"\"Projects reality into the mind (update state) using tanh activation.\"\"\"\n",
        "        pre_act = np.dot(self.W_in, input_vector) + np.dot(self.W_res, self.state)\n",
        "        # Apply nonlinearity\n",
        "        self.state = np.tanh(pre_act).astype(np.float32)\n",
        "        # Sanitize state to avoid NaN/inf\n",
        "        np.nan_to_num(self.state, copy=False, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "\n",
        "    def dream(self) -> np.ndarray:\n",
        "        \"\"\"Predicts the next moment based on current state with clipping.\"\"\"\n",
        "        out = np.dot(self.W_out, self.state).astype(np.float32)\n",
        "        # Clean and clip the output\n",
        "        np.nan_to_num(out, copy=False, nan=0.0, posinf=self.out_clip, neginf=-self.out_clip)\n",
        "        out = np.clip(out, -self.out_clip, self.out_clip, out=out)\n",
        "        return out\n",
        "\n",
        "    def learn(self,\n",
        "              target_vector: np.ndarray,\n",
        "              learning_rate: float = 0.1,\n",
        "              prediction: np.ndarray | None = None) -> float:\n",
        "        \"\"\"\n",
        "        Update readout weights to minimize surprise using a simple delta rule with\n",
        "        weight decay. If prediction is provided, it will be used to compute the\n",
        "        error; otherwise the current dream() will be used.\n",
        "        \"\"\"\n",
        "        if prediction is None:\n",
        "            prediction = self.dream()\n",
        "\n",
        "        error = (target_vector - prediction).astype(np.float32)\n",
        "        # Outer product update\n",
        "        update = np.outer(error, self.state)\n",
        "        self.W_out += learning_rate * update.astype(np.float32)\n",
        "        # Apply weight decay to gradually shrink weights and prevent blowup\n",
        "        if self.weight_decay > 0.0:\n",
        "            self.W_out *= (1.0 - self.weight_decay)\n",
        "        # Sanitize weights\n",
        "        np.nan_to_num(self.W_out, copy=False, nan=0.0, posinf=self.out_clip, neginf=-self.out_clip)\n",
        "        return float(np.linalg.norm(error))\n",
        "\n",
        "\n",
        "class NoeticEncoder:\n",
        "    \"\"\"Encodes a data stream into the NoeticStream format using predictive coding.\"\"\"\n",
        "    def __init__(self,\n",
        "                 n_features: int,\n",
        "                 surprise_threshold: float = 0.05,\n",
        "                 use_adaptive_surprise: bool = False,\n",
        "                 ema_alpha: float = 1e-3,\n",
        "                 sigma_k: float = 2.0,\n",
        "                 weight_decay: float = 1e-5,\n",
        "                 out_clip: float = 10.0):\n",
        "        self.brain = ReservoirCompute(n_features, weight_decay=weight_decay, out_clip=out_clip)\n",
        "        self.surprise_threshold = surprise_threshold\n",
        "        self.use_adaptive_surprise = use_adaptive_surprise\n",
        "        self.ema_alpha = ema_alpha\n",
        "        self.sigma_k = sigma_k\n",
        "        self.ema_mean = 0.0\n",
        "        self.ema_var = 1.0\n",
        "        self.surprise_count = 0\n",
        "        self.min_surprise = float('inf')\n",
        "        self.max_surprise = 0.0\n",
        "        self._last_sigma = 0.0\n",
        "\n",
        "    def _update_surprise_stats(self, s: float) -> None:\n",
        "        self.surprise_count += 1\n",
        "        self.min_surprise = min(self.min_surprise, s)\n",
        "        self.max_surprise = max(self.max_surprise, s)\n",
        "        if self.surprise_count == 1:\n",
        "            self.ema_mean = s\n",
        "            self.ema_var = 0.0\n",
        "            self._last_sigma = 0.0\n",
        "            return\n",
        "        # Exponential moving statistics\n",
        "        delta = s - self.ema_mean\n",
        "        self.ema_mean += self.ema_alpha * delta\n",
        "        self.ema_var = (1.0 - self.ema_alpha) * (self.ema_var + self.ema_alpha * delta * delta)\n",
        "        self._last_sigma = float(np.sqrt(max(self.ema_var, 1e-12)))\n",
        "\n",
        "    def _is_epiphany(self, surprise: float) -> bool:\n",
        "        if not self.use_adaptive_surprise or self.surprise_count < 100:\n",
        "            return surprise > self.surprise_threshold\n",
        "        sigma = max(self._last_sigma, 1e-6)\n",
        "        adaptive_thresh = self.ema_mean + self.sigma_k * sigma\n",
        "        eff_thresh = max(self.surprise_threshold, adaptive_thresh)\n",
        "        return surprise > eff_thresh\n",
        "\n",
        "    def compress(self,\n",
        "                 data_generator: Generator[np.ndarray, None, None],\n",
        "                 output_file) -> None:\n",
        "        # Write magic and header\n",
        "        output_file.write(NOETIC_MAGIC)\n",
        "        header = struct.pack(\n",
        "            HEADER_FORMAT,\n",
        "            NOETIC_VERSION,\n",
        "            self.brain.n_inputs,\n",
        "            self.brain.n_reservoir,\n",
        "            self.brain.spectral_radius,\n",
        "            self.brain.seed\n",
        "        )\n",
        "        output_file.write(header)\n",
        "        # RLE buffer\n",
        "        chunk_buffer = []\n",
        "        total_frames = 0\n",
        "        epiphanies = 0\n",
        "        for frame in data_generator:\n",
        "            frame = frame.astype(np.float32)\n",
        "            dream = self.brain.dream()\n",
        "            surprise = float(np.linalg.norm(frame - dream))\n",
        "            self._update_surprise_stats(surprise)\n",
        "            if self._is_epiphany(surprise):\n",
        "                if chunk_buffer:\n",
        "                    count = len(chunk_buffer)\n",
        "                    output_file.write(struct.pack('BB', 0, count))\n",
        "                    chunk_buffer = []\n",
        "                output_file.write(struct.pack('B', 1))\n",
        "                output_file.write(frame.tobytes())\n",
        "                self.brain.learn(frame, prediction=dream)\n",
        "                self.brain.listen(frame)\n",
        "                epiphanies += 1\n",
        "            else:\n",
        "                chunk_buffer.append(0)\n",
        "                self.brain.listen(frame)\n",
        "                if len(chunk_buffer) == 255:\n",
        "                    output_file.write(struct.pack('BB', 0, 255))\n",
        "                    chunk_buffer = []\n",
        "            total_frames += 1\n",
        "        if chunk_buffer:\n",
        "            count = len(chunk_buffer)\n",
        "            output_file.write(struct.pack('BB', 0, count))\n",
        "        # Print stats\n",
        "        cognitive_load = epiphanies / total_frames * 100.0 if total_frames else 0.0\n",
        "        sigma = self._last_sigma\n",
        "        print(f\"[Noetic Stats] Total Moments: {total_frames} | Epiphanies (Writes): {epiphanies}\")\n",
        "        print(f\"Cognitive Load: {cognitive_load:.2f}% (Percentage of reality that was surprising)\")\n",
        "        print(f\"Surprise: mean{self.ema_mean:.4f}, std{sigma:.4f}, min{self.min_surprise:.4f}, max{self.max_surprise:.4f}\")\n",
        "        if self.use_adaptive_surprise and self.surprise_count >= 100:\n",
        "            eff_thresh = max(self.surprise_threshold, self.ema_mean + self.sigma_k * sigma)\n",
        "            print(f\"Effective adaptive threshold{eff_thresh:.4f}\")\n",
        "\n",
        "\n",
        "class NoeticDecoder:\n",
        "    \"\"\"Decodes a NoeticStream to reconstruct the original data sequence.\"\"\"\n",
        "    def decompress(self, input_file) -> Generator[np.ndarray, None, None]:\n",
        "        magic = input_file.read(4)\n",
        "        if magic != NOETIC_MAGIC:\n",
        "            raise ValueError(\"Invalid Noetic Stream (bad magic)\")\n",
        "        header_bytes = input_file.read(HEADER_SIZE)\n",
        "        if len(header_bytes) != HEADER_SIZE:\n",
        "            raise ValueError(\"Truncated Noetic header\")\n",
        "        version, n_inputs, n_res, spec_rad, seed = struct.unpack(HEADER_FORMAT, header_bytes)\n",
        "        if version != NOETIC_VERSION:\n",
        "            raise ValueError(f\"Unsupported Noetic version: {version}\")\n",
        "        brain = ReservoirCompute(\n",
        "            n_inputs=int(n_inputs),\n",
        "            n_reservoir=int(n_res),\n",
        "            spectral_radius=float(spec_rad),\n",
        "            seed=int(seed)\n",
        "        )\n",
        "        while True:\n",
        "            flag_byte = input_file.read(1)\n",
        "            if not flag_byte:\n",
        "                break\n",
        "            flag = struct.unpack('B', flag_byte)[0]\n",
        "            if flag == 1:\n",
        "                data = input_file.read(n_inputs * 4)\n",
        "                if len(data) != n_inputs * 4:\n",
        "                    raise ValueError(\"Truncated epiphany frame in stream\")\n",
        "                frame = np.frombuffer(data, dtype=np.float32)\n",
        "                yield frame\n",
        "                dream = brain.dream()\n",
        "                brain.learn(frame, prediction=dream)\n",
        "                brain.listen(frame)\n",
        "            elif flag == 0:\n",
        "                count_bytes = input_file.read(1)\n",
        "                if len(count_bytes) != 1:\n",
        "                    raise ValueError(\"Truncated RLE count in stream\")\n",
        "                count = struct.unpack('B', count_bytes)[0]\n",
        "                for _ in range(count):\n",
        "                    dream = brain.dream()\n",
        "                    yield dream\n",
        "                    brain.listen(dream)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown flag in stream: {flag}\")\n",
        "\n",
        "\n",
        "# Simulation: Lorenz attractor projected into 128 dimensions\n",
        "def chaos_generator(steps: int) -> Generator[np.ndarray, None, None]:\n",
        "    dt = 0.01\n",
        "    x, y, z = 0.1, 0.0, 0.0\n",
        "    np.random.seed(42)\n",
        "    projection = np.random.randn(3, 128).astype(np.float32)\n",
        "    for _ in range(steps):\n",
        "        dx = 10 * (y - x)\n",
        "        dy = x * (28 - z) - y\n",
        "        dz = x * y - (8/3) * z\n",
        "        x += dx * dt\n",
        "        y += dy * dt\n",
        "        z += dz * dt\n",
        "        state = np.array([x, y, z], dtype=np.float32)\n",
        "        sensors = np.dot(state, projection) / 50.0\n",
        "        yield sensors\n",
        "\n",
        "\n",
        "def test_noetic(steps: int = 50000, features: int = 128, threshold: float = 0.05,\n",
        "                use_adaptive: bool = False, weight_decay: float = 1e-5,\n",
        "                out_clip: float = 10.0) -> None:\n",
        "    \"\"\"Runs a full encode/decode cycle on Lorenz chaos and reports stats.\"\"\"\n",
        "    import tempfile\n",
        "    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
        "        filename = tmp.name\n",
        "    encoder = NoeticEncoder(features, surprise_threshold=threshold,\n",
        "                            use_adaptive_surprise=use_adaptive,\n",
        "                            weight_decay=weight_decay, out_clip=out_clip)\n",
        "    with open(filename, 'wb') as f:\n",
        "        encoder.compress(chaos_generator(steps), f)\n",
        "    raw_size = steps * features * 4\n",
        "    file_size = os.path.getsize(filename)\n",
        "    ratio = raw_size / file_size if file_size else float('inf')\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"EPISTEMIC RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Raw Reality:    {raw_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Stored Wisdom:  {file_size / 1024 / 1024:.2f} MB\")\n",
        "    print(f\"Ratio:          {ratio:.2f}x\")\n",
        "    # Verification\n",
        "    decoder = NoeticDecoder()\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "    with open(filename, 'rb') as f:\n",
        "        gen = chaos_generator(steps)\n",
        "        dec_gen = decoder.decompress(f)\n",
        "        for real, dream in zip(gen, dec_gen):\n",
        "            diff = real.astype(np.float32) - dream.astype(np.float32)\n",
        "            diff = np.clip(diff, -1e3, 1e3)\n",
        "            mse += float(np.mean(diff * diff))\n",
        "            count += 1\n",
        "    if count > 0:\n",
        "        print(f\"Dream Fidelity (MSE): {mse / count:.6f}\")\n",
        "        print(f\"Decoded Frames:       {count} (Expected: {steps})\")\n",
        "    os.remove(filename)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Default test when executed directly\n",
        "    test_noetic()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rXod7a2Qx-k",
        "outputId": "a3370313-dc76-48a0-d761-18f56237e9b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Noetic Stats] Total Moments: 50000 | Epiphanies (Writes): 49980\n",
            "Cognitive Load: 99.96% (Percentage of reality that was surprising)\n",
            "Surprise: mean111.5553, std0.8889, min0.0093, max115.9761\n",
            "\n",
            "========================================\n",
            "EPISTEMIC RESULTS\n",
            "========================================\n",
            "Raw Reality:    24.41 MB\n",
            "Stored Wisdom:  24.45 MB\n",
            "Ratio:          1.00x\n",
            "Dream Fidelity (MSE): 0.000000\n",
            "Decoded Frames:       50000 (Expected: 50000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: RESERVOIR WITH RLS (FORCE LEARNING)\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine upgraded with Recursive Least Squares (RLS).\n",
        "    Now includes input scaling to ensure non-linearity.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=400, spectral_radius=0.95, forgetting=0.99, leak_rate=1.0):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "        self.leak_rate = leak_rate\n",
        "\n",
        "        np.random.seed(42)\n",
        "        # Input projection (Scaled up to drive non-linearity)\n",
        "        self.W_in = np.random.uniform(-1.0, 1.0, (n_reservoir, n_inputs)) * 0.5\n",
        "\n",
        "        # Internal dynamics\n",
        "        self.W_res = np.random.normal(0, 1, (n_reservoir, n_reservoir))\n",
        "        radius = np.max(np.abs(np.linalg.eigvals(self.W_res)))\n",
        "        self.W_res = self.W_res * (spectral_radius / radius)\n",
        "\n",
        "        self.state = np.zeros(n_reservoir)\n",
        "        self.W_out = np.zeros((n_inputs, n_reservoir))\n",
        "\n",
        "        # RLS Covariance\n",
        "        self.P = np.eye(n_reservoir) / 0.001 # High initial plasticity\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "    def listen(self, u):\n",
        "        # x = (1-a)x + a*tanh(Win*u + Wres*x)\n",
        "        pre = np.dot(self.W_in, u) + np.dot(self.W_res, self.state)\n",
        "        self.state = (1 - self.leak_rate) * self.state + self.leak_rate * np.tanh(pre)\n",
        "\n",
        "    def dream(self):\n",
        "        return np.dot(self.W_out, self.state)\n",
        "\n",
        "    def adapt(self, target):\n",
        "        r = self.state\n",
        "        y = np.dot(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        # Standard RLS\n",
        "        Pr = np.dot(self.P, r)\n",
        "        rPr = np.dot(r.T, Pr)\n",
        "        gain_k = Pr / (self.forgetting + rPr)\n",
        "\n",
        "        self.P = (self.P - np.outer(gain_k, Pr)) / self.forgetting\n",
        "        self.W_out += np.outer(e, gain_k)\n",
        "\n",
        "        return np.linalg.norm(e)\n",
        "\n",
        "# ==============================================================================\n",
        "# HOMEOSTATIC COMPRESSOR\n",
        "# ==============================================================================\n",
        "\n",
        "def rls_compress_demo():\n",
        "    print(\">>> INITIALIZING HOMEOSTATIC NOETIC ENGINE...\")\n",
        "    print(\">>> Concept: 'If overwhelmed, ignore the details.'\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    WARMUP = 2000\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos.rls\"\n",
        "\n",
        "    # Chaos Generator (Lorenz)\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            # Normalize to approx -1 to 1\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float32)\n",
        "\n",
        "    brain = RLS_Reservoir(FEATURES)\n",
        "\n",
        "    # HOMEOSTASIS PARAMETERS\n",
        "    current_threshold = 0.05 # Start looser\n",
        "    target_surprise_rate = 0.15 # Aim for 15% Epiphanies (85% Compression)\n",
        "    adaptation_rate = 0.001 # How fast to adjust threshold\n",
        "\n",
        "    epiphanies = 0\n",
        "    packet_buffer = []\n",
        "\n",
        "    # Detailed Stats Tracking\n",
        "    total_error_mag = 0.0\n",
        "    threshold_history = []\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame in enumerate(gen):\n",
        "            # Warmup: Just learn\n",
        "            if i < WARMUP:\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "                if i % 500 == 0:\n",
        "                    print(f\"\\r[Warmup] Synapsing... {i}/{WARMUP}\", end=\"\")\n",
        "                continue\n",
        "\n",
        "            if i == WARMUP: print(\"\\n>>> Active Compression Started.\")\n",
        "\n",
        "            # 1. Dream\n",
        "            dream = brain.dream()\n",
        "\n",
        "            # 2. Reality Check\n",
        "            error_vec = frame - dream\n",
        "            error_mag = np.linalg.norm(error_vec)\n",
        "\n",
        "            # Track stats\n",
        "            total_error_mag += error_mag\n",
        "            threshold_history.append(current_threshold)\n",
        "\n",
        "            # 3. Judge (Using Dynamic Threshold)\n",
        "            is_surprise = error_mag > current_threshold\n",
        "\n",
        "            if is_surprise:\n",
        "                # Write Epiphany (Flag 1 + Data)\n",
        "                # In production we'd use 1 bit, here we use 1 byte for simplicity\n",
        "                packet_buffer.append(b'\\x01' + frame.tobytes())\n",
        "                epiphanies += 1\n",
        "\n",
        "                # Force Learn\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "            else:\n",
        "                # Write Silence (Flag 0)\n",
        "                packet_buffer.append(b'\\x00')\n",
        "\n",
        "                # Passive Listen (Internalize the dream as reality)\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "\n",
        "            # 4. Homeostasis (Adjust Threshold)\n",
        "            if is_surprise:\n",
        "                current_threshold *= (1.0 + adaptation_rate)\n",
        "            else:\n",
        "                current_threshold *= (1.0 - (adaptation_rate * (target_surprise_rate / (1 - target_surprise_rate))))\n",
        "\n",
        "            # Hard limits\n",
        "            current_threshold = max(0.001, min(current_threshold, 2.0))\n",
        "\n",
        "    # Flush buffer\n",
        "    with open(FILENAME, 'ab') as f:\n",
        "        for pkt in packet_buffer:\n",
        "            f.write(pkt)\n",
        "\n",
        "    # Stats Calculation\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    final_surprise_rate = epiphanies / STEPS * 100\n",
        "    avg_error = total_error_mag / STEPS\n",
        "    avg_threshold = sum(threshold_history) / len(threshold_history)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"HOMEOSTATIC ANALYSIS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Data Source:      Lorenz Attractor (Deterministic Chaos)\")\n",
        "    print(f\"Total Steps:      {STEPS}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Epiphanies:       {epiphanies} (Surprises)\")\n",
        "    print(f\"Silence Frames:   {STEPS - epiphanies} (Predicted Correctly)\")\n",
        "    print(f\"Cognitive Load:   {final_surprise_rate:.2f}%\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Avg Pred Error:   {avg_error:.4f} (MSE approx)\")\n",
        "    print(f\"Avg Threshold:    {avg_threshold:.4f} (Sensitivity)\")\n",
        "    print(f\"Final Threshold:  {current_threshold:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Raw Size:         {raw_size/1024:.2f} KB\")\n",
        "    print(f\"Compressed Size:  {file_size/1024:.2f} KB\")\n",
        "    print(f\"COMPRESSION RATIO: {ratio:.2f}x\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    if ratio > 2.0:\n",
        "        print(\"\\n\\u2705 SUCCESS: Homeostasis achieved balance.\")\n",
        "        print(\"   The system realized it couldn't be perfect, so it chose to be efficient.\")\n",
        "    else:\n",
        "        print(\"\\n\\u26a0\\ufe0f FAILURE: Chaos overwhelmed the regulator.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rls_compress_demo()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PElyCXgSPzO",
        "outputId": "24eda527-1c91-4271-86e3-e3a5da05e1a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INITIALIZING HOMEOSTATIC NOETIC ENGINE...\n",
            ">>> Concept: 'If overwhelmed, ignore the details.'\n",
            "[Warmup] Synapsing... 1500/2000\n",
            ">>> Active Compression Started.\n",
            "\n",
            "========================================\n",
            "HOMEOSTATIC ANALYSIS\n",
            "========================================\n",
            "Data Source:      Lorenz Attractor (Deterministic Chaos)\n",
            "Total Steps:      50000\n",
            "----------------------------------------\n",
            "Epiphanies:       9279 (Surprises)\n",
            "Silence Frames:   40721 (Predicted Correctly)\n",
            "Cognitive Load:   18.56%\n",
            "----------------------------------------\n",
            "Avg Pred Error:   0.2463 (MSE approx)\n",
            "Avg Threshold:    0.4066 (Sensitivity)\n",
            "Final Threshold:  0.4033\n",
            "----------------------------------------\n",
            "Raw Size:         12500.00 KB\n",
            "Compressed Size:  2368.58 KB\n",
            "COMPRESSION RATIO: 5.28x\n",
            "========================================\n",
            "\n",
            " SUCCESS: Homeostasis achieved balance.\n",
            "   The system realized it couldn't be perfect, so it chose to be efficient.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION & GPU SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "# Detect T4 or other CUDA device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\">>> Hardware Acceleration: {device} ({torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'})\")\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: RESERVOIR WITH RLS (GPU ACCELERATED)\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    \"\"\"\n",
        "    A Liquid State Machine on GPU.\n",
        "    Uses PyTorch for massive matrix operations (2000x2000).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_inputs, n_reservoir=2000, spectral_radius=0.95, forgetting=0.99, leak_rate=1.0):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_reservoir = n_reservoir\n",
        "        self.leak_rate = leak_rate\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "        # Initialize on CPU first for reproducible RNG, then move to GPU\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # Input projection (Scaled)\n",
        "        # Shape: [Reservoir, Inputs]\n",
        "        self.W_in = (torch.rand(n_reservoir, n_inputs, device=device) * 2 - 1) * 0.5\n",
        "\n",
        "        # Internal dynamics\n",
        "        # Shape: [Reservoir, Reservoir]\n",
        "        W_res_cpu = torch.randn(n_reservoir, n_reservoir)\n",
        "\n",
        "        # Spectral Radius Tuning\n",
        "        # Eigendecomposition is expensive, do on CPU once\n",
        "        print(f\"[GPU Init] Tuning spectral radius for {n_reservoir} neurons...\")\n",
        "        eigenvalues = torch.linalg.eigvals(W_res_cpu)\n",
        "        radius = torch.max(torch.abs(eigenvalues))\n",
        "        W_res_cpu = W_res_cpu * (spectral_radius / radius)\n",
        "        self.W_res = W_res_cpu.to(device)\n",
        "\n",
        "        # State Vector\n",
        "        self.state = torch.zeros(n_reservoir, device=device)\n",
        "\n",
        "        # Readout Weights (The memory)\n",
        "        # Shape: [Inputs, Reservoir] (Transposed standard W_out for easier matmul)\n",
        "        self.W_out = torch.zeros(n_inputs, n_reservoir, device=device)\n",
        "\n",
        "        # RLS Covariance Matrix\n",
        "        # Shape: [Reservoir, Reservoir]\n",
        "        self.P = torch.eye(n_reservoir, device=device) / 0.001\n",
        "\n",
        "    def listen(self, u):\n",
        "        \"\"\" Update internal state on GPU \"\"\"\n",
        "        # u shape: [Inputs]\n",
        "        # W_in @ u -> [Reservoir]\n",
        "\n",
        "        # Pre-activation: Win*u + Wres*state\n",
        "        input_injection = torch.matmul(self.W_in, u)\n",
        "        internal_flow = torch.matmul(self.W_res, self.state)\n",
        "\n",
        "        pre = input_injection + internal_flow\n",
        "\n",
        "        # Leaky update\n",
        "        self.state = (1 - self.leak_rate) * self.state + self.leak_rate * torch.tanh(pre)\n",
        "\n",
        "    def dream(self):\n",
        "        \"\"\" Predict next step \"\"\"\n",
        "        # W_out @ state -> [Inputs]\n",
        "        return torch.matmul(self.W_out, self.state)\n",
        "\n",
        "    def adapt(self, target):\n",
        "        \"\"\"\n",
        "        Recursive Least Squares (RLS) on GPU.\n",
        "        This involves O(N^2) operations, perfect for Tensor Cores.\n",
        "        \"\"\"\n",
        "        r = self.state\n",
        "        # Current prediction\n",
        "        y = torch.matmul(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        # RLS Calculation\n",
        "        # Pr = P @ r\n",
        "        Pr = torch.matmul(self.P, r)\n",
        "\n",
        "        # rPr = r.T @ P @ r (Scalar-like)\n",
        "        rPr = torch.dot(r, Pr)\n",
        "\n",
        "        # gain_k = Pr / (forgetting + rPr)\n",
        "        gain_k = Pr / (self.forgetting + rPr)\n",
        "\n",
        "        # Update P (Covariance)\n",
        "        # P = (P - outer(k, Pr)) / lambda\n",
        "        # outer(k, Pr) creates [Reservoir, Reservoir] rank-1 update\n",
        "        update_term = torch.ger(gain_k, Pr)\n",
        "        self.P = (self.P - update_term) / self.forgetting\n",
        "\n",
        "        # Update Weights\n",
        "        # W_out += outer(e, k)\n",
        "        weight_update = torch.ger(e, gain_k)\n",
        "        self.W_out += weight_update\n",
        "\n",
        "        return torch.norm(e).item()\n",
        "\n",
        "# ==============================================================================\n",
        "# HOMEOSTATIC COMPRESSOR (GPU ENABLED)\n",
        "# ==============================================================================\n",
        "\n",
        "def rls_compress_demo():\n",
        "    print(\">>> INITIALIZING HOMEOSTATIC NOETIC ENGINE (GPU EDITION)...\")\n",
        "\n",
        "    STEPS = 100000\n",
        "    WARMUP = 2000\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos.rls\"\n",
        "\n",
        "    # Chaos Generator (Lorenz) - CPU Generation is fine, we move to GPU in loop\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float32)\n",
        "\n",
        "    # Initialize GPU Brain\n",
        "    brain = RLS_Reservoir(FEATURES)\n",
        "\n",
        "    # Parameters\n",
        "    current_threshold = 0.05\n",
        "    target_surprise_rate = 0.15\n",
        "    adaptation_rate = 0.001\n",
        "\n",
        "    epiphanies = 0\n",
        "    packet_buffer = []\n",
        "\n",
        "    total_error_mag = 0.0\n",
        "    threshold_history = []\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame_np in enumerate(gen):\n",
        "            # Move Reality to GPU\n",
        "            frame = torch.from_numpy(frame_np).to(device)\n",
        "\n",
        "            # Warmup\n",
        "            if i < WARMUP:\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "                if i % 500 == 0:\n",
        "                    print(f\"\\r[Warmup] Synapsing on T4... {i}/{WARMUP}\", end=\"\")\n",
        "                continue\n",
        "\n",
        "            if i == WARMUP: print(\"\\n>>> Active Compression Started.\")\n",
        "\n",
        "            # 1. Dream\n",
        "            dream = brain.dream()\n",
        "\n",
        "            # 2. Reality Check\n",
        "            error_vec = frame - dream\n",
        "            error_mag = torch.norm(error_vec).item()\n",
        "\n",
        "            total_error_mag += error_mag\n",
        "            threshold_history.append(current_threshold)\n",
        "\n",
        "            # 3. Judge\n",
        "            is_surprise = error_mag > current_threshold\n",
        "\n",
        "            if is_surprise:\n",
        "                # Write Epiphany (Move back to CPU for disk write)\n",
        "                packet_buffer.append(b'\\x01' + frame_np.tobytes())\n",
        "                epiphanies += 1\n",
        "\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "            else:\n",
        "                # Write Silence\n",
        "                packet_buffer.append(b'\\x00')\n",
        "\n",
        "                brain.listen(frame)\n",
        "                brain.adapt(frame)\n",
        "\n",
        "            # 4. Homeostasis\n",
        "            if is_surprise:\n",
        "                current_threshold *= (1.0 + adaptation_rate)\n",
        "            else:\n",
        "                current_threshold *= (1.0 - (adaptation_rate * (target_surprise_rate / (1 - target_surprise_rate))))\n",
        "\n",
        "            current_threshold = max(0.001, min(current_threshold, 2.0))\n",
        "\n",
        "            # Periodic status\n",
        "            if i % 10000 == 0:\n",
        "                sys.stdout.write(f\"\\rProcessing Frame {i}/{STEPS+WARMUP} | Threshold: {current_threshold:.4f}\")\n",
        "\n",
        "    # Flush\n",
        "    with open(FILENAME, 'ab') as f:\n",
        "        for pkt in packet_buffer:\n",
        "            f.write(pkt)\n",
        "\n",
        "    # Stats\n",
        "    raw_size = STEPS * FEATURES * 4\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    final_surprise_rate = epiphanies / STEPS * 100\n",
        "    avg_error = total_error_mag / STEPS\n",
        "    avg_threshold = sum(threshold_history) / len(threshold_history)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*40)\n",
        "    print(\"GPU HOMEOSTATIC ANALYSIS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Device:           {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Neurons:          {brain.n_reservoir} (Upscaled for T4)\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Epiphanies:       {epiphanies}\")\n",
        "    print(f\"Cognitive Load:   {final_surprise_rate:.2f}%\")\n",
        "    print(f\"Avg Pred Error:   {avg_error:.4f}\")\n",
        "    print(f\"Final Threshold:  {current_threshold:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Raw Size:         {raw_size/1024:.2f} KB\")\n",
        "    print(f\"Compressed Size:  {file_size/1024:.2f} KB\")\n",
        "    print(f\"COMPRESSION RATIO: {ratio:.2f}x\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"WARNING: No T4 GPU detected. This will be slow on CPU.\")\n",
        "    rls_compress_demo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw184sAXXEKV",
        "outputId": "ef05bff7-9293-44ec-c5f1-20f800ac76bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Hardware Acceleration: cuda (Tesla T4)\n",
            ">>> INITIALIZING HOMEOSTATIC NOETIC ENGINE (GPU EDITION)...\n",
            "[GPU Init] Tuning spectral radius for 2000 neurons...\n",
            "[Warmup] Synapsing on T4... 1500/2000\n",
            ">>> Active Compression Started.\n",
            "Processing Frame 100000/102000 | Threshold: 0.0010\n",
            "\n",
            "========================================\n",
            "GPU HOMEOSTATIC ANALYSIS\n",
            "========================================\n",
            "Device:           Tesla T4\n",
            "Neurons:          2000 (Upscaled for T4)\n",
            "----------------------------------------\n",
            "Epiphanies:       2404\n",
            "Cognitive Load:   2.40%\n",
            "Avg Pred Error:   nan\n",
            "Final Threshold:  0.0010\n",
            "----------------------------------------\n",
            "Raw Size:         25000.00 KB\n",
            "Compressed Size:  698.66 KB\n",
            "COMPRESSION RATIO: 35.78x\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import struct\n",
        "import os\n",
        "import sys\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION & GPU SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\">>> Hardware: {device} | Precision: Float64 (Lossless Sync)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# THE BRAINS\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    def __init__(self, n_inputs, n_reservoir=2000, spectral_radius=0.99, forgetting=0.999, leak_rate=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.leak_rate = leak_rate\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "        # Deterministic Initialization\n",
        "        torch.manual_seed(42)\n",
        "        self.W_in = (torch.rand(n_reservoir, n_inputs, device=device) * 2 - 1) * 0.1\n",
        "\n",
        "        W_res_cpu = torch.randn(n_reservoir, n_reservoir)\n",
        "        eigenvalues = torch.linalg.eigvals(W_res_cpu)\n",
        "        self.W_res = (W_res_cpu * (spectral_radius / torch.max(torch.abs(eigenvalues)))).to(device)\n",
        "\n",
        "        self.state = torch.zeros(n_reservoir, device=device)\n",
        "        self.W_out = torch.zeros(n_inputs, n_reservoir, device=device)\n",
        "        self.P = torch.eye(n_reservoir, device=device) / 0.001\n",
        "\n",
        "    def listen(self, u):\n",
        "        pre = torch.matmul(self.W_in, u) + torch.matmul(self.W_res, self.state)\n",
        "        self.state = (1 - self.leak_rate) * self.state + self.leak_rate * torch.tanh(pre)\n",
        "\n",
        "    def dream(self):\n",
        "        return torch.matmul(self.W_out, self.state)\n",
        "\n",
        "    def adapt(self, target):\n",
        "        r = self.state\n",
        "        y = torch.matmul(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        Pr = torch.matmul(self.P, r)\n",
        "        rPr = torch.dot(r, Pr)\n",
        "        # Robust Ridge Regression to prevent blowups\n",
        "        gain_k = Pr / (self.forgetting + rPr + 1e-6)\n",
        "\n",
        "        self.P = (self.P - torch.ger(gain_k, Pr)) / self.forgetting\n",
        "        self.W_out += torch.ger(e, gain_k)\n",
        "\n",
        "class NewtonianPredictor:\n",
        "    def __init__(self, n_features):\n",
        "        self.pos = torch.zeros(n_features, device=device)\n",
        "        self.vel = torch.zeros(n_features, device=device)\n",
        "        self.acc = torch.zeros(n_features, device=device)\n",
        "\n",
        "    def predict(self):\n",
        "        return self.pos + self.vel + (0.5 * self.acc)\n",
        "\n",
        "    def update(self, current_pos):\n",
        "        new_vel = current_pos - self.pos\n",
        "        new_acc = new_vel - self.vel\n",
        "        self.pos = current_pos\n",
        "        self.vel = new_vel\n",
        "        self.acc = new_acc\n",
        "\n",
        "# ==============================================================================\n",
        "# THE SYNCED BICAMERAL ENGINE\n",
        "# ==============================================================================\n",
        "\n",
        "def bicameral_demo_v4():\n",
        "    print(\">>> INITIALIZING BICAMERAL ENGINE V4 (EXPLICIT SIGNALING)...\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    WARMUP = 2000\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos_v4.bin\"\n",
        "\n",
        "    # Chaos Generator\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float64)\n",
        "\n",
        "    # Initialize Brains\n",
        "    right_brain = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    left_brain = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    current_threshold = 0.05\n",
        "    target_surprise = 0.10\n",
        "    adaptation = 0.002\n",
        "\n",
        "    packet_buffer = []\n",
        "    stats = {\"epiphany\": 0, \"left_wins\": 0, \"right_wins\": 0}\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame_np in enumerate(gen):\n",
        "            frame = torch.from_numpy(frame_np).to(device)\n",
        "\n",
        "            # Warmup\n",
        "            if i < WARMUP:\n",
        "                right_brain.listen(frame)\n",
        "                right_brain.adapt(frame)\n",
        "                left_brain.update(frame)\n",
        "                if i % 500 == 0: sys.stdout.write(f\"\\r[Warmup] {i}/{WARMUP}\")\n",
        "                continue\n",
        "\n",
        "            if i == WARMUP: print(\"\\n>>> Engine Active.\")\n",
        "\n",
        "            # 1. Consult Both Brains\n",
        "            pred_L = left_brain.predict()\n",
        "            pred_R = right_brain.dream()\n",
        "\n",
        "            # 2. Reality Check\n",
        "            err_L = torch.norm(frame - pred_L).item()\n",
        "            err_R = torch.norm(frame - pred_R).item()\n",
        "\n",
        "            # 3. Determine Winner\n",
        "            if err_L < err_R:\n",
        "                best_pred = pred_L\n",
        "                best_err = err_L\n",
        "                winner = \"left\"\n",
        "            else:\n",
        "                best_pred = pred_R\n",
        "                best_err = err_R\n",
        "                winner = \"right\"\n",
        "\n",
        "            # 4. Compress\n",
        "            is_surprise = best_err > current_threshold\n",
        "\n",
        "            if is_surprise:\n",
        "                # >>> EPIPHANY (Flag 1) <<<\n",
        "                packet_buffer.append(b'\\x01' + frame_np.tobytes())\n",
        "                stats[\"epiphany\"] += 1\n",
        "\n",
        "                # SYNC: Everyone learns Truth\n",
        "                right_brain.listen(frame)\n",
        "                right_brain.adapt(frame)\n",
        "                left_brain.update(frame)\n",
        "\n",
        "                current_threshold *= (1.0 + adaptation)\n",
        "            else:\n",
        "                # >>> SILENCE (Explicit Flags) <<<\n",
        "                # We tell the decoder WHO won so it updates the same way we do.\n",
        "\n",
        "                if winner == \"left\":\n",
        "                    packet_buffer.append(b'\\x00') # Flag 0 = Left Win\n",
        "                    stats[\"left_wins\"] += 1\n",
        "                else:\n",
        "                    packet_buffer.append(b'\\x02') # Flag 2 = Right Win\n",
        "                    stats[\"right_wins\"] += 1\n",
        "\n",
        "                # SYNC: Everyone believes the Best Prediction (The Lie)\n",
        "                right_brain.listen(best_pred)\n",
        "                # right_brain.adapt(best_pred) # Reinforcement disabled to prevent drift loops\n",
        "                left_brain.update(best_pred)\n",
        "\n",
        "                current_threshold *= (1.0 - (adaptation * (target_surprise / (1 - target_surprise))))\n",
        "\n",
        "            current_threshold = max(0.0001, min(current_threshold, 1.0))\n",
        "\n",
        "            if i % 10000 == 0:\n",
        "                sys.stdout.write(f\"\\rFrame {i} | Thresh: {current_threshold:.5f} | L/R: {stats['left_wins']}/{stats['right_wins']}\")\n",
        "\n",
        "    # Flush\n",
        "    with open(FILENAME, 'ab') as f:\n",
        "        for pkt in packet_buffer: f.write(pkt)\n",
        "\n",
        "    # Stats\n",
        "    raw_size = STEPS * FEATURES * 8\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*40)\n",
        "    print(\"BICAMERAL V4 RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Epiphanies:       {stats['epiphany']}\")\n",
        "    print(f\"Left Wins (Lin):  {stats['left_wins']}\")\n",
        "    print(f\"Right Wins (Ch):  {stats['right_wins']}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Raw Size:         {raw_size/1024/1024:.2f} MB\")\n",
        "    print(f\"Compressed Size:  {file_size/1024/1024:.2f} MB\")\n",
        "    print(f\"COMPRESSION RATIO: {ratio:.2f}x\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DECODER (VERIFICATION)\n",
        "    # ==========================================================================\n",
        "    print(\"\\n>>> VERIFYING (DECODING)...\")\n",
        "\n",
        "    # Re-init brains (Reset state)\n",
        "    dec_right = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    dec_left = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    # Truth Stream\n",
        "    truth_gen = lorenz(STEPS + WARMUP)\n",
        "    for _ in range(WARMUP):\n",
        "        warmup_frame = torch.from_numpy(next(truth_gen)).to(device)\n",
        "        dec_right.listen(warmup_frame)\n",
        "        dec_right.adapt(warmup_frame)\n",
        "        dec_left.update(warmup_frame)\n",
        "\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        _ = f.read(4)\n",
        "\n",
        "        while True:\n",
        "            flag_byte = f.read(1)\n",
        "            if not flag_byte: break\n",
        "            flag = struct.unpack('B', flag_byte)[0]\n",
        "\n",
        "            # 1. Calculate Candidates\n",
        "            pL = dec_left.predict()\n",
        "            pR = dec_right.dream()\n",
        "\n",
        "            if flag == 1: # Epiphany\n",
        "                data = f.read(FEATURES * 8)\n",
        "                # Make a writable copy to avoid PyTorch warning\n",
        "                frame_np = np.frombuffer(data, dtype=np.float64).copy()\n",
        "                truth = torch.from_numpy(frame_np).to(device)\n",
        "\n",
        "                # Sync\n",
        "                dec_right.listen(truth)\n",
        "                dec_right.adapt(truth)\n",
        "                dec_left.update(truth)\n",
        "\n",
        "                # Check error against Ground Truth\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(truth - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 0: # Silence (LEFT WON)\n",
        "                consensus = pL\n",
        "\n",
        "                # Sync\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 2: # Silence (RIGHT WON)\n",
        "                consensus = pR\n",
        "\n",
        "                # Sync\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            count += 1\n",
        "            if count % 10000 == 0: sys.stdout.write(f\"\\rDecoding {count}...\")\n",
        "\n",
        "    print(f\"\\n\\nFinal MSE (Fidelity): {mse/count:.6f}\")\n",
        "\n",
        "    if mse/count < 0.1:\n",
        "        print(\" SUCCESS: High Fidelity Reconstruction.\")\n",
        "        print(\"   The Encoder and Decoder stayed in perfect psychic sync.\")\n",
        "    else:\n",
        "        print(\" FAILURE: Drift is still occurring.\")\n",
        "\n",
        "    os.remove(FILENAME)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bicameral_demo_v4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvGG3HUziY8g",
        "outputId": "08e40381-0b38-4177-e216-1129ae161990"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Hardware: cuda | Precision: Float64 (Lossless Sync)\n",
            ">>> INITIALIZING BICAMERAL ENGINE V4 (EXPLICIT SIGNALING)...\n",
            "[Warmup] 1500/2000\n",
            ">>> Engine Active.\n",
            "Frame 50000 | Thresh: 0.99978 | L/R: 18138/19311\n",
            "\n",
            "========================================\n",
            "BICAMERAL V4 RESULTS\n",
            "========================================\n",
            "Epiphanies:       10837\n",
            "Left Wins (Lin):  18923\n",
            "Right Wins (Ch):  20240\n",
            "----------------------------------------\n",
            "Raw Size:         24.41 MB\n",
            "Compressed Size:  5.34 MB\n",
            "COMPRESSION RATIO: 4.57x\n",
            "\n",
            ">>> VERIFYING (DECODING)...\n",
            "Decoding 50000...\n",
            "\n",
            "Final MSE (Fidelity): 0.278837\n",
            " FAILURE: Drift is still occurring.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# ==============================================================================\n",
        "# CRITICAL: PHYSICS INITIALIZATION (MUST BE FIRST)\n",
        "# ==============================================================================\n",
        "# We must define the workspace config BEFORE any CUDA operations occur.\n",
        "# This allocates the specific buffer needed for bit-exact matrix multiplication.\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import struct\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION & GPU DETERMINISM\n",
        "# ==============================================================================\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# FORCE DETERMINISM (The \"God Mode\" Switch)\n",
        "torch.manual_seed(42)\n",
        "try:\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "except RuntimeError as e:\n",
        "    print(f\"Warning: Could not enforce determinism: {e}\")\n",
        "\n",
        "print(f\">>> Hardware: {device} | Precision: Float64\")\n",
        "print(\">>> Mode: Deep Orchestrated Collapse (State Quantization)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# THE COLLAPSE FUNCTION\n",
        "# ==============================================================================\n",
        "\n",
        "def orch_or_collapse(tensor, precision=100000.0):\n",
        "    \"\"\"\n",
        "    Collapses a quantum/analog float state onto a discrete lattice.\n",
        "    Increased precision to 100,000 to allow finer dynamics while ensuring lock.\n",
        "    \"\"\"\n",
        "    return torch.round(tensor * precision) / precision\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: QUANTIZED RESERVOIR\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    def __init__(self, n_inputs, n_reservoir=2000, spectral_radius=0.95, forgetting=0.999, leak_rate=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.leak_rate = leak_rate\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "        torch.manual_seed(42)\n",
        "        self.W_in = (torch.rand(n_reservoir, n_inputs, device=device) * 2 - 1) * 0.1\n",
        "\n",
        "        W_res_cpu = torch.randn(n_reservoir, n_reservoir)\n",
        "        eigenvalues = torch.linalg.eigvals(W_res_cpu)\n",
        "        self.W_res = (W_res_cpu * (spectral_radius / torch.max(torch.abs(eigenvalues)))).to(device)\n",
        "\n",
        "        # State must be initialized on the grid\n",
        "        self.state = torch.zeros(n_reservoir, device=device)\n",
        "        self.W_out = torch.zeros(n_inputs, n_reservoir, device=device)\n",
        "        self.P = torch.eye(n_reservoir, device=device) / 0.001\n",
        "\n",
        "    def listen(self, u):\n",
        "        # 1. Collapse Input\n",
        "        u = orch_or_collapse(u)\n",
        "\n",
        "        # 2. Analog Calculation\n",
        "        pre = torch.matmul(self.W_in, u) + torch.matmul(self.W_res, self.state)\n",
        "        new_state = (1 - self.leak_rate) * self.state + self.leak_rate * torch.tanh(pre)\n",
        "\n",
        "        # 3. ORCH-OR COLLAPSE (The Fix)\n",
        "        # We force the internal neurons to snap to the grid before the next step.\n",
        "        self.state = orch_or_collapse(new_state)\n",
        "\n",
        "    def dream(self):\n",
        "        # Output is naturally collapsed if W_out and State are stable?\n",
        "        # No, let's collapse the dream too to be safe.\n",
        "        return orch_or_collapse(torch.matmul(self.W_out, self.state))\n",
        "\n",
        "    def adapt(self, target):\n",
        "        target = orch_or_collapse(target)\n",
        "\n",
        "        r = self.state # Already collapsed from listen()\n",
        "        y = torch.matmul(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        Pr = torch.matmul(self.P, r)\n",
        "        rPr = torch.dot(r, Pr)\n",
        "        gain_k = Pr / (self.forgetting + rPr + 1e-6)\n",
        "\n",
        "        self.P = (self.P - torch.ger(gain_k, Pr)) / self.forgetting\n",
        "        self.W_out += torch.ger(e, gain_k)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE LEFT BRAIN: QUANTIZED NEWTONIAN\n",
        "# ==============================================================================\n",
        "\n",
        "class NewtonianPredictor:\n",
        "    def __init__(self, n_features):\n",
        "        self.pos = torch.zeros(n_features, device=device)\n",
        "        self.vel = torch.zeros(n_features, device=device)\n",
        "        self.acc = torch.zeros(n_features, device=device)\n",
        "\n",
        "    def predict(self):\n",
        "        # Kinematics are analog...\n",
        "        pred = self.pos + self.vel + (0.5 * self.acc)\n",
        "        # ...but the prediction snaps to reality.\n",
        "        return orch_or_collapse(pred)\n",
        "\n",
        "    def update(self, current_pos):\n",
        "        current_pos = orch_or_collapse(current_pos)\n",
        "\n",
        "        new_vel = current_pos - self.pos\n",
        "        new_acc = new_vel - self.vel\n",
        "\n",
        "        # State Collapse: Physics variables must be grid-locked\n",
        "        self.pos = current_pos\n",
        "        self.vel = orch_or_collapse(new_vel)\n",
        "        self.acc = orch_or_collapse(new_acc)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE DEEP ORCHESTRATED ENGINE (V6)\n",
        "# ==============================================================================\n",
        "\n",
        "def bicameral_demo_v6():\n",
        "    print(\">>> INITIALIZING BICAMERAL ENGINE V6 (DEEP COLLAPSE)...\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    WARMUP = 2000\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos_v6.bin\"\n",
        "\n",
        "    # Chaos Generator\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float64)\n",
        "\n",
        "    right_brain = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    left_brain = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    current_threshold = 0.05\n",
        "    target_surprise = 0.10\n",
        "    adaptation = 0.002\n",
        "\n",
        "    packet_buffer = []\n",
        "    stats = {\"epiphany\": 0, \"left_wins\": 0, \"right_wins\": 0}\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame_np in enumerate(gen):\n",
        "            # 1. Reality Collapse (The Input)\n",
        "            frame = orch_or_collapse(torch.from_numpy(frame_np).to(device))\n",
        "\n",
        "            if i < WARMUP:\n",
        "                right_brain.listen(frame)\n",
        "                right_brain.adapt(frame)\n",
        "                left_brain.update(frame)\n",
        "                if i % 500 == 0: sys.stdout.write(f\"\\r[Warmup] {i}/{WARMUP}\")\n",
        "                continue\n",
        "\n",
        "            if i == WARMUP: print(\"\\n>>> Engine Active.\")\n",
        "\n",
        "            # 2. Consult Brains (Output is Collapsed by .dream()/.predict())\n",
        "            pred_L = left_brain.predict()\n",
        "            pred_R = right_brain.dream()\n",
        "\n",
        "            # 3. Select\n",
        "            err_L = torch.norm(frame - pred_L).item()\n",
        "            err_R = torch.norm(frame - pred_R).item()\n",
        "\n",
        "            if err_L < err_R:\n",
        "                best_pred = pred_L\n",
        "                best_err = err_L\n",
        "                winner = \"left\"\n",
        "            else:\n",
        "                best_pred = pred_R\n",
        "                best_err = err_R\n",
        "                winner = \"right\"\n",
        "\n",
        "            # Note: best_pred is already collapsed by the brain functions\n",
        "            consensus = best_pred\n",
        "\n",
        "            # 4. Judge\n",
        "            is_surprise = best_err > current_threshold\n",
        "\n",
        "            if is_surprise:\n",
        "                # >>> EPIPHANY <<<\n",
        "                packet_buffer.append(b'\\x01' + frame_np.tobytes())\n",
        "                stats[\"epiphany\"] += 1\n",
        "\n",
        "                # SYNC: Truth\n",
        "                right_brain.listen(frame)\n",
        "                right_brain.adapt(frame)\n",
        "                left_brain.update(frame)\n",
        "\n",
        "                current_threshold *= (1.0 + adaptation)\n",
        "            else:\n",
        "                # >>> SILENCE <<<\n",
        "                if winner == \"left\":\n",
        "                    packet_buffer.append(b'\\x00')\n",
        "                    stats[\"left_wins\"] += 1\n",
        "                else:\n",
        "                    packet_buffer.append(b'\\x02')\n",
        "                    stats[\"right_wins\"] += 1\n",
        "\n",
        "                # SYNC: Lie\n",
        "                right_brain.listen(consensus)\n",
        "                # Note: We do NOT adapt RLS on the lie. We just update state.\n",
        "                left_brain.update(consensus)\n",
        "\n",
        "                current_threshold *= (1.0 - (adaptation * (target_surprise / (1 - target_surprise))))\n",
        "\n",
        "            current_threshold = max(0.0001, min(current_threshold, 1.0))\n",
        "\n",
        "            if i % 10000 == 0:\n",
        "                sys.stdout.write(f\"\\rFrame {i} | Thresh: {current_threshold:.5f} | L/R: {stats['left_wins']}/{stats['right_wins']}\")\n",
        "\n",
        "    with open(FILENAME, 'ab') as f:\n",
        "        for pkt in packet_buffer: f.write(pkt)\n",
        "\n",
        "    raw_size = STEPS * FEATURES * 8\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*40)\n",
        "    print(\"DEEP ORCHESTRATED RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Epiphanies:       {stats['epiphany']}\")\n",
        "    print(f\"Left (Newtonian): {stats['left_wins']}\")\n",
        "    print(f\"Right (Chaotic):  {stats['right_wins']}\")\n",
        "    print(f\"COMPRESSION RATIO: {ratio:.2f}x\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DECODER\n",
        "    # ==========================================================================\n",
        "    print(\"\\n>>> VERIFYING (DECODING)...\")\n",
        "\n",
        "    dec_right = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    dec_left = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    truth_gen = lorenz(STEPS + WARMUP)\n",
        "    for _ in range(WARMUP):\n",
        "        warmup_frame = orch_or_collapse(torch.from_numpy(next(truth_gen)).to(device))\n",
        "        dec_right.listen(warmup_frame)\n",
        "        dec_right.adapt(warmup_frame)\n",
        "        dec_left.update(warmup_frame)\n",
        "\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        _ = f.read(4)\n",
        "\n",
        "        while True:\n",
        "            flag_byte = f.read(1)\n",
        "            if not flag_byte: break\n",
        "            flag = struct.unpack('B', flag_byte)[0]\n",
        "\n",
        "            pL = dec_left.predict()\n",
        "            pR = dec_right.dream()\n",
        "\n",
        "            if flag == 1: # Epiphany\n",
        "                data = f.read(FEATURES * 8)\n",
        "                truth = torch.from_numpy(np.frombuffer(data, dtype=np.float64)).to(device)\n",
        "                truth = orch_or_collapse(truth) # Lock incoming truth\n",
        "\n",
        "                dec_right.listen(truth)\n",
        "                dec_right.adapt(truth)\n",
        "                dec_left.update(truth)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                # Compare collapsed truth to raw truth\n",
        "                mse += torch.norm(truth - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 0: # Left\n",
        "                consensus = pL\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 2: # Right\n",
        "                consensus = pR\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            count += 1\n",
        "            if count % 10000 == 0: sys.stdout.write(f\"\\rDecoding {count}...\")\n",
        "\n",
        "    print(f\"\\n\\nFinal MSE (Fidelity): {mse/count:.6f}\")\n",
        "\n",
        "    if mse/count < 0.01:\n",
        "        print(\" SUCCESS: Deep State Collapse prevented drift.\")\n",
        "    else:\n",
        "        print(\" FAILURE: Chaos is untamable.\")\n",
        "\n",
        "    os.remove(FILENAME)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bicameral_demo_v6()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-LCNXE6pHq3",
        "outputId": "70ee925b-1d0a-4f9e-e6ff-6a2630717170"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Hardware: cuda | Precision: Float64\n",
            ">>> Mode: Deep Orchestrated Collapse (State Quantization)\n",
            ">>> INITIALIZING BICAMERAL ENGINE V6 (DEEP COLLAPSE)...\n",
            "[Warmup] 1500/2000\n",
            ">>> Engine Active.\n",
            "Frame 50000 | Thresh: 0.99978 | L/R: 17599/19847\n",
            "\n",
            "========================================\n",
            "DEEP ORCHESTRATED RESULTS\n",
            "========================================\n",
            "Epiphanies:       10839\n",
            "Left (Newtonian): 18519\n",
            "Right (Chaotic):  20642\n",
            "COMPRESSION RATIO: 4.57x\n",
            "\n",
            ">>> VERIFYING (DECODING)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2083006227.py:276: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  truth = torch.from_numpy(np.frombuffer(data, dtype=np.float64)).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding 50000...\n",
            "\n",
            "Final MSE (Fidelity): 0.282945\n",
            " FAILURE: Chaos is untamable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# ==============================================================================\n",
        "# CRITICAL: PHYSICS INITIALIZATION (MUST BE FIRST)\n",
        "# ==============================================================================\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import struct\n",
        "import hashlib\n",
        "from typing import Tuple, Generator\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION & GPU DETERMINISM\n",
        "# ==============================================================================\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# FORCE DETERMINISM\n",
        "torch.manual_seed(42)\n",
        "try:\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "except RuntimeError as e:\n",
        "    if \"CUBLAS_WORKSPACE_CONFIG\" in str(e):\n",
        "        print(\"CRITICAL: Please restart runtime. CUDA context is dirty.\")\n",
        "        sys.exit(1)\n",
        "    raise e\n",
        "\n",
        "print(f\">>> Hardware: {device} | Precision: Float64\")\n",
        "print(\">>> Forensic Suite: Active (Plasticity, Entropy, Telepathy Check)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# THE COLLAPSE FUNCTION\n",
        "# ==============================================================================\n",
        "\n",
        "def orch_or_collapse(tensor, precision=100000.0):\n",
        "    return torch.round(tensor * precision) / precision\n",
        "\n",
        "# ==============================================================================\n",
        "# THE RIGHT BRAIN: QUANTIZED RESERVOIR\n",
        "# ==============================================================================\n",
        "\n",
        "class RLS_Reservoir:\n",
        "    def __init__(self, n_inputs, n_reservoir=2000, spectral_radius=0.95, forgetting=0.999, leak_rate=0.9):\n",
        "        self.n_inputs = n_inputs\n",
        "        self.leak_rate = leak_rate\n",
        "        self.forgetting = forgetting\n",
        "\n",
        "        torch.manual_seed(42)\n",
        "        self.W_in = (torch.rand(n_reservoir, n_inputs, device=device) * 2 - 1) * 0.1\n",
        "\n",
        "        W_res_cpu = torch.randn(n_reservoir, n_reservoir)\n",
        "        eigenvalues = torch.linalg.eigvals(W_res_cpu)\n",
        "        self.W_res = (W_res_cpu * (spectral_radius / torch.max(torch.abs(eigenvalues)))).to(device)\n",
        "\n",
        "        self.state = torch.zeros(n_reservoir, device=device)\n",
        "        self.W_out = torch.zeros(n_inputs, n_reservoir, device=device)\n",
        "        self.P = torch.eye(n_reservoir, device=device) / 0.001\n",
        "\n",
        "    def listen(self, u):\n",
        "        u = orch_or_collapse(u)\n",
        "        pre = torch.matmul(self.W_in, u) + torch.matmul(self.W_res, self.state)\n",
        "        new_state = (1 - self.leak_rate) * self.state + self.leak_rate * torch.tanh(pre)\n",
        "        self.state = orch_or_collapse(new_state)\n",
        "\n",
        "    def dream(self):\n",
        "        return orch_or_collapse(torch.matmul(self.W_out, self.state))\n",
        "\n",
        "    def adapt(self, target):\n",
        "        target = orch_or_collapse(target)\n",
        "        r = self.state\n",
        "        y = torch.matmul(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        Pr = torch.matmul(self.P, r)\n",
        "        rPr = torch.dot(r, Pr)\n",
        "        gain_k = Pr / (self.forgetting + rPr + 1e-6)\n",
        "\n",
        "        self.P = (self.P - torch.ger(gain_k, Pr)) / self.forgetting\n",
        "\n",
        "        # Track Plasticity (Magnitude of synaptic change)\n",
        "        weight_update = torch.ger(e, gain_k)\n",
        "        plasticity = torch.norm(weight_update).item()\n",
        "\n",
        "        self.W_out += weight_update\n",
        "        return plasticity\n",
        "\n",
        "    def get_synaptic_hash(self):\n",
        "        \"\"\" Returns a cryptographic signature of the current brain state \"\"\"\n",
        "        # We move to CPU numpy to hash raw bytes\n",
        "        w_bytes = self.W_out.cpu().numpy().tobytes()\n",
        "        p_bytes = self.P.cpu().numpy().tobytes()\n",
        "        return hashlib.sha256(w_bytes + p_bytes).hexdigest()[:16]\n",
        "\n",
        "# ==============================================================================\n",
        "# THE LEFT BRAIN: QUANTIZED NEWTONIAN\n",
        "# ==============================================================================\n",
        "\n",
        "class NewtonianPredictor:\n",
        "    def __init__(self, n_features):\n",
        "        self.pos = torch.zeros(n_features, device=device)\n",
        "        self.vel = torch.zeros(n_features, device=device)\n",
        "        self.acc = torch.zeros(n_features, device=device)\n",
        "\n",
        "    def predict(self):\n",
        "        pred = self.pos + self.vel + (0.5 * self.acc)\n",
        "        return orch_or_collapse(pred)\n",
        "\n",
        "    def update(self, current_pos):\n",
        "        current_pos = orch_or_collapse(current_pos)\n",
        "        new_vel = current_pos - self.pos\n",
        "        new_acc = new_vel - self.vel\n",
        "        self.pos = current_pos\n",
        "        self.vel = orch_or_collapse(new_vel)\n",
        "        self.acc = orch_or_collapse(new_acc)\n",
        "\n",
        "# ==============================================================================\n",
        "# FORENSIC TOOLS\n",
        "# ==============================================================================\n",
        "\n",
        "def calculate_entropy(data):\n",
        "    if not data: return 0.0\n",
        "    counts = {}\n",
        "    for byte in data:\n",
        "        counts[byte] = counts.get(byte, 0) + 1\n",
        "\n",
        "    entropy = 0\n",
        "    total = len(data)\n",
        "    for count in counts.values():\n",
        "        p = count / total\n",
        "        entropy -= p * np.log2(p)\n",
        "    return entropy\n",
        "\n",
        "# ==============================================================================\n",
        "# THE DEEP ORCHESTRATED ENGINE (V6 + FORENSICS)\n",
        "# ==============================================================================\n",
        "\n",
        "def bicameral_demo_v6():\n",
        "    print(\">>> INITIALIZING BICAMERAL ENGINE V6 (FORENSIC MODE)...\")\n",
        "\n",
        "    STEPS = 50000\n",
        "    WARMUP = 2000\n",
        "    FEATURES = 64\n",
        "    FILENAME = \"chaos_v6.bin\"\n",
        "\n",
        "    # Chaos Generator\n",
        "    def lorenz(steps):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42)\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(steps):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float64)\n",
        "\n",
        "    right_brain = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    left_brain = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    current_threshold = 0.05\n",
        "    target_surprise = 0.10\n",
        "    adaptation = 0.002\n",
        "\n",
        "    packet_buffer = []\n",
        "    stats = {\"epiphany\": 0, \"left_wins\": 0, \"right_wins\": 0}\n",
        "    plasticity_log = []\n",
        "\n",
        "    gen = lorenz(STEPS + WARMUP)\n",
        "\n",
        "    with open(FILENAME, 'wb') as f:\n",
        "        f.write(struct.pack('<I', FEATURES))\n",
        "\n",
        "        for i, frame_np in enumerate(gen):\n",
        "            frame = orch_or_collapse(torch.from_numpy(frame_np).to(device))\n",
        "\n",
        "            if i < WARMUP:\n",
        "                right_brain.listen(frame)\n",
        "                right_brain.adapt(frame)\n",
        "                left_brain.update(frame)\n",
        "                if i % 500 == 0: sys.stdout.write(f\"\\r[Warmup] {i}/{WARMUP}\")\n",
        "                continue\n",
        "\n",
        "            if i == WARMUP: print(\"\\n>>> Engine Active.\")\n",
        "\n",
        "            # 1. Consult Brains\n",
        "            pred_L = left_brain.predict()\n",
        "            pred_R = right_brain.dream()\n",
        "\n",
        "            # 2. Selection\n",
        "            err_L = torch.norm(frame - pred_L).item()\n",
        "            err_R = torch.norm(frame - pred_R).item()\n",
        "\n",
        "            if err_L < err_R:\n",
        "                best_pred = pred_L\n",
        "                best_err = err_L\n",
        "                winner = \"left\"\n",
        "            else:\n",
        "                best_pred = pred_R\n",
        "                best_err = err_R\n",
        "                winner = \"right\"\n",
        "\n",
        "            consensus = best_pred\n",
        "\n",
        "            # 3. Judge\n",
        "            is_surprise = best_err > current_threshold\n",
        "\n",
        "            if is_surprise:\n",
        "                # EPIPHANY\n",
        "                packet_buffer.append(b'\\x01' + frame_np.tobytes())\n",
        "                stats[\"epiphany\"] += 1\n",
        "\n",
        "                right_brain.listen(frame)\n",
        "                p = right_brain.adapt(frame) # Track plasticity\n",
        "                plasticity_log.append(p)\n",
        "                left_brain.update(frame)\n",
        "\n",
        "                current_threshold *= (1.0 + adaptation)\n",
        "            else:\n",
        "                # SILENCE\n",
        "                if winner == \"left\":\n",
        "                    packet_buffer.append(b'\\x00')\n",
        "                    stats[\"left_wins\"] += 1\n",
        "                else:\n",
        "                    packet_buffer.append(b'\\x02')\n",
        "                    stats[\"right_wins\"] += 1\n",
        "\n",
        "                right_brain.listen(consensus)\n",
        "                left_brain.update(consensus)\n",
        "\n",
        "                # Decay plasticity record (0 for silence)\n",
        "                plasticity_log.append(0.0)\n",
        "\n",
        "                current_threshold *= (1.0 - (adaptation * (target_surprise / (1 - target_surprise))))\n",
        "\n",
        "            current_threshold = max(0.0001, min(current_threshold, 1.0))\n",
        "\n",
        "            if i % 10000 == 0:\n",
        "                sys.stdout.write(f\"\\rFrame {i} | Thresh: {current_threshold:.5f} | Plas: {np.mean(plasticity_log[-100:]):.5f}\")\n",
        "\n",
        "        # END OF STREAM: APPEND BRAIN SIGNATURE\n",
        "        # This allows the decoder to verify if its brain matches the encoder's brain\n",
        "        brain_hash = right_brain.get_synaptic_hash()\n",
        "        print(f\"\\n\\n>>> ENCODER BRAIN HASH: {brain_hash}\")\n",
        "\n",
        "        # We append a special footer: [MAGIC_FOOTER][HASH_BYTES]\n",
        "        # Magic: \"SYNC\"\n",
        "        packet_buffer.append(b'SYNC' + brain_hash.encode('utf-8'))\n",
        "\n",
        "    # Flush to Disk\n",
        "    final_bytes = b''.join(packet_buffer)\n",
        "    with open(FILENAME, 'ab') as f:\n",
        "        f.write(final_bytes)\n",
        "\n",
        "    # Forensic Analysis\n",
        "    raw_size = STEPS * FEATURES * 8\n",
        "    file_size = os.path.getsize(FILENAME)\n",
        "    ratio = raw_size / file_size\n",
        "    entropy = calculate_entropy(final_bytes)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"FORENSIC REPORT\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Epiphanies:       {stats['epiphany']}\")\n",
        "    print(f\"Linear Wins:      {stats['left_wins']}\")\n",
        "    print(f\"Chaotic Wins:     {stats['right_wins']}\")\n",
        "    print(f\"Avg Plasticity:   {np.mean(plasticity_log):.5f} (Synaptic Change/Step)\")\n",
        "    print(f\"Bitstream Entropy:{entropy:.4f} bits/byte (Max 8.0)\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Compression Ratio: {ratio:.2f}x\")\n",
        "\n",
        "    # ==========================================================================\n",
        "    # DECODER VERIFICATION\n",
        "    # ==========================================================================\n",
        "    print(\"\\n>>> VERIFYING (DECODING)...\")\n",
        "\n",
        "    dec_right = RLS_Reservoir(FEATURES, n_reservoir=2000)\n",
        "    dec_left = NewtonianPredictor(FEATURES)\n",
        "\n",
        "    truth_gen = lorenz(STEPS + WARMUP)\n",
        "    for _ in range(WARMUP):\n",
        "        warmup_frame = orch_or_collapse(torch.from_numpy(next(truth_gen)).to(device))\n",
        "        dec_right.listen(warmup_frame)\n",
        "        dec_right.adapt(warmup_frame)\n",
        "        dec_left.update(warmup_frame)\n",
        "\n",
        "    mse = 0.0\n",
        "    count = 0\n",
        "\n",
        "    with open(FILENAME, 'rb') as f:\n",
        "        # Read Header\n",
        "        _ = f.read(4)\n",
        "\n",
        "        # We need to read until the end, but handle the footer.\n",
        "        # Hack: We know the footer is 4 (\"SYNC\") + 16 (Hash) = 20 bytes\n",
        "        # We read stream char by char? Slow.\n",
        "        # We'll just read and handle normally, catching the SYNC flag manually.\n",
        "        # In a real format, we'd have length headers.\n",
        "\n",
        "        # Efficient read strategy:\n",
        "        # We know the simulation length is STEPS. We decode exactly that many frames.\n",
        "        # Then we check the remaining bytes for the hash.\n",
        "\n",
        "        for _ in range(STEPS):\n",
        "            flag_byte = f.read(1)\n",
        "            if not flag_byte: break\n",
        "            flag = struct.unpack('B', flag_byte)[0]\n",
        "\n",
        "            pL = dec_left.predict()\n",
        "            pR = dec_right.dream()\n",
        "\n",
        "            if flag == 1: # Epiphany\n",
        "                data = f.read(FEATURES * 8)\n",
        "                truth = torch.from_numpy(np.frombuffer(data, dtype=np.float64)).to(device)\n",
        "                truth = orch_or_collapse(truth)\n",
        "\n",
        "                dec_right.listen(truth)\n",
        "                dec_right.adapt(truth)\n",
        "                dec_left.update(truth)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(truth - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 0: # Left\n",
        "                consensus = orch_or_collapse(pL)\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            elif flag == 2: # Right\n",
        "                consensus = orch_or_collapse(pR)\n",
        "                dec_right.listen(consensus)\n",
        "                dec_left.update(consensus)\n",
        "\n",
        "                real_truth = torch.from_numpy(next(truth_gen)).to(device)\n",
        "                mse += torch.norm(consensus - real_truth).item() ** 2\n",
        "\n",
        "            count += 1\n",
        "            if count % 10000 == 0: sys.stdout.write(f\"\\rDecoding {count}...\")\n",
        "\n",
        "        # TELEPATHY CHECK\n",
        "        # Read footer\n",
        "        footer_magic = f.read(4)\n",
        "        if footer_magic == b'SYNC':\n",
        "            target_hash = f.read(16).decode('utf-8')\n",
        "            my_hash = dec_right.get_synaptic_hash()\n",
        "\n",
        "            print(f\"\\n\\n>>> DECODER BRAIN HASH: {my_hash}\")\n",
        "            print(f\">>> TARGET BRAIN HASH:  {target_hash}\")\n",
        "\n",
        "            if my_hash == target_hash:\n",
        "                print(\" SYNAPTIC LOCK CONFIRMED: Brains are identical.\")\n",
        "            else:\n",
        "                print(\" SYNAPTIC MISMATCH: Brains drifted.\")\n",
        "        else:\n",
        "            print(\"\\n Footer missing or corrupt.\")\n",
        "\n",
        "    print(f\"Final MSE (Fidelity): {mse/count:.6f}\")\n",
        "\n",
        "    if mse/count < 0.01:\n",
        "        print(\" SUCCESS: Physics preserved.\")\n",
        "    else:\n",
        "        print(\" FAILURE: Decoherence.\")\n",
        "\n",
        "    os.remove(FILENAME)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bicameral_demo_v6()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHHwkPQXvc0t",
        "outputId": "ec0943fc-65d9-435e-ef80-cbbb1287ed20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Hardware: cuda | Precision: Float64\n",
            ">>> Forensic Suite: Active (Plasticity, Entropy, Telepathy Check)\n",
            ">>> INITIALIZING BICAMERAL ENGINE V6 (FORENSIC MODE)...\n",
            "[Warmup] 1500/2000\n",
            ">>> Engine Active.\n",
            "Frame 50000 | Thresh: 0.99978 | Plas: 0.02801\n",
            "\n",
            ">>> ENCODER BRAIN HASH: 4cc402335775da4c\n",
            "\n",
            "========================================\n",
            "FORENSIC REPORT\n",
            "========================================\n",
            "Epiphanies:       10839\n",
            "Linear Wins:      18519\n",
            "Chaotic Wins:     20642\n",
            "Avg Plasticity:   0.00855 (Synaptic Change/Step)\n",
            "Bitstream Entropy:7.6359 bits/byte (Max 8.0)\n",
            "----------------------------------------\n",
            "Compression Ratio: 4.57x\n",
            "\n",
            ">>> VERIFYING (DECODING)...\n",
            "Decoding 50000...\n",
            "\n",
            ">>> DECODER BRAIN HASH: 4cc402335775da4c\n",
            ">>> TARGET BRAIN HASH:  4cc402335775da4c\n",
            " SYNAPTIC LOCK CONFIRMED: Brains are identical.\n",
            "Final MSE (Fidelity): 0.282945\n",
            " FAILURE: Decoherence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# ==============================================================================\n",
        "# PHYSICS INITIALIZATION\n",
        "# ==============================================================================\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# ==============================================================================\n",
        "# CONFIGURATION\n",
        "# ==============================================================================\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# FORCE DETERMINISM (For Fair Competition)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "try:\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "except RuntimeError:\n",
        "    pass # Colab might need restart, handled in logs\n",
        "\n",
        "print(f\">>> Evolutionary Environment: {device}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# THE GENOME (BRAIN DNA)\n",
        "# ==============================================================================\n",
        "\n",
        "@dataclass\n",
        "class BrainDNA:\n",
        "    n_reservoir: int = 500        # Brain Size (Smaller for speed during evo)\n",
        "    spectral_radius: float = 0.95 # Chaos Level\n",
        "    leak_rate: float = 0.9        # Reaction Speed\n",
        "    input_scaling: float = 0.5    # Sensitivity\n",
        "    forgetting: float = 0.999     # Plasticity\n",
        "\n",
        "    def mutate(self):\n",
        "        \"\"\" Randomly tweak genes for the next generation \"\"\"\n",
        "        mutation_rate = 0.1\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            self.spectral_radius += np.random.normal(0, 0.05)\n",
        "            self.spectral_radius = np.clip(self.spectral_radius, 0.1, 1.5)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            self.leak_rate += np.random.normal(0, 0.05)\n",
        "            self.leak_rate = np.clip(self.leak_rate, 0.01, 1.0)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            self.input_scaling += np.random.normal(0, 0.1)\n",
        "            self.input_scaling = max(0.01, self.input_scaling)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            # Forgetting factor is sensitive, tweak closer to 1.0\n",
        "            self.forgetting += np.random.normal(0, 0.001)\n",
        "            self.forgetting = np.clip(self.forgetting, 0.90, 1.0)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE COLLAPSE (ORCH-OR)\n",
        "# ==============================================================================\n",
        "\n",
        "def orch_or_collapse(tensor, precision=100000.0):\n",
        "    return torch.round(tensor * precision) / precision\n",
        "\n",
        "# ==============================================================================\n",
        "# THE SUBJECT (RESERVOIR)\n",
        "# ==============================================================================\n",
        "\n",
        "class EvolvableReservoir:\n",
        "    def __init__(self, n_inputs, dna: BrainDNA):\n",
        "        self.dna = dna\n",
        "        self.n_inputs = n_inputs\n",
        "\n",
        "        # Deterministic weights for fairness, but modulated by DNA\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # W_in modulated by Input Scaling DNA\n",
        "        self.W_in = (torch.rand(dna.n_reservoir, n_inputs, device=device) * 2 - 1) * dna.input_scaling\n",
        "\n",
        "        # W_res modulated by Spectral Radius DNA\n",
        "        W_res_cpu = torch.randn(dna.n_reservoir, dna.n_reservoir)\n",
        "        eigenvalues = torch.linalg.eigvals(W_res_cpu)\n",
        "        max_eig = torch.max(torch.abs(eigenvalues))\n",
        "        self.W_res = (W_res_cpu * (dna.spectral_radius / max_eig)).to(device)\n",
        "\n",
        "        self.state = torch.zeros(dna.n_reservoir, device=device)\n",
        "        self.W_out = torch.zeros(n_inputs, dna.n_reservoir, device=device)\n",
        "        self.P = torch.eye(dna.n_reservoir, device=device) / 0.001\n",
        "\n",
        "    def listen(self, u):\n",
        "        u = orch_or_collapse(u)\n",
        "        pre = torch.matmul(self.W_in, u) + torch.matmul(self.W_res, self.state)\n",
        "\n",
        "        # Leak Rate DNA\n",
        "        new_state = (1 - self.dna.leak_rate) * self.state + self.dna.leak_rate * torch.tanh(pre)\n",
        "        self.state = orch_or_collapse(new_state)\n",
        "\n",
        "    def dream(self):\n",
        "        return orch_or_collapse(torch.matmul(self.W_out, self.state))\n",
        "\n",
        "    def adapt(self, target):\n",
        "        target = orch_or_collapse(target)\n",
        "        r = self.state\n",
        "        y = torch.matmul(self.W_out, r)\n",
        "        e = target - y\n",
        "\n",
        "        Pr = torch.matmul(self.P, r)\n",
        "        rPr = torch.dot(r, Pr)\n",
        "\n",
        "        # Forgetting Factor DNA\n",
        "        gain_k = Pr / (self.dna.forgetting + rPr + 1e-6)\n",
        "\n",
        "        self.P = (self.P - torch.ger(gain_k, Pr)) / self.dna.forgetting\n",
        "        self.W_out += torch.ger(e, gain_k)\n",
        "\n",
        "# ==============================================================================\n",
        "# THE SIMULATION (FITNESS TEST)\n",
        "# ==============================================================================\n",
        "\n",
        "def run_simulation(dna: BrainDNA, steps=5000):\n",
        "    \"\"\"\n",
        "    Runs the Bicameral Engine with a specific DNA configuration.\n",
        "    Returns the Compression Ratio (Fitness).\n",
        "    \"\"\"\n",
        "    FEATURES = 64\n",
        "    brain = EvolvableReservoir(FEATURES, dna)\n",
        "\n",
        "    # Linear Predictor (Standard Newtonian, shared by all)\n",
        "    # We perform a simplified simulation:\n",
        "    # We only measure how often the Reservoir (Right Brain) beats the threshold.\n",
        "\n",
        "    # Generate Chaos\n",
        "    def lorenz(n):\n",
        "        dt=0.01; x,y,z=0.1,0.,0.\n",
        "        np.random.seed(42) # Same challenge for everyone\n",
        "        proj = np.random.randn(3, FEATURES)\n",
        "        for _ in range(n):\n",
        "            dx=10*(y-x); dy=x*(28-z)-y; dz=x*y-(8/3)*z\n",
        "            x+=dx*dt; y+=dy*dt; z+=dz*dt\n",
        "            s = np.dot(np.array([x,y,z]), proj) / 25.0\n",
        "            yield s.astype(np.float64)\n",
        "\n",
        "    gen = lorenz(steps)\n",
        "\n",
        "    epiphanies = 0\n",
        "    silence = 0\n",
        "\n",
        "    # Threshold settings (Fixed for fair comparison)\n",
        "    threshold = 0.05\n",
        "    target_surprise = 0.10\n",
        "    adapt_rate = 0.005\n",
        "\n",
        "    for i, frame_np in enumerate(gen):\n",
        "        frame = orch_or_collapse(torch.from_numpy(frame_np).to(device))\n",
        "\n",
        "        # Warmup (Free learning)\n",
        "        if i < 500:\n",
        "            brain.listen(frame)\n",
        "            brain.adapt(frame)\n",
        "            continue\n",
        "\n",
        "        # Test\n",
        "        dream = brain.dream()\n",
        "        error = torch.norm(frame - dream).item()\n",
        "\n",
        "        if error > threshold:\n",
        "            # Surprise -> Epiphany\n",
        "            epiphanies += 1\n",
        "            brain.listen(frame)\n",
        "            brain.adapt(frame)\n",
        "            threshold *= (1.0 + adapt_rate)\n",
        "        else:\n",
        "            # Silence -> Success\n",
        "            silence += 1\n",
        "            brain.listen(dream) # Sync on dream\n",
        "            threshold *= (1.0 - (adapt_rate * (target_surprise / (1 - target_surprise))))\n",
        "\n",
        "        threshold = max(0.0001, min(threshold, 0.15))\n",
        "\n",
        "    # Fitness Calculation\n",
        "    # Higher Ratio = Better\n",
        "    # Ratio approx = Total Steps / Epiphanies\n",
        "    if epiphanies == 0: return 0 # Avoid div by zero, something broke\n",
        "\n",
        "    ratio = (steps - 500) / epiphanies\n",
        "    return ratio\n",
        "\n",
        "# ==============================================================================\n",
        "# THE EVOLUTIONARY LOOP\n",
        "# ==============================================================================\n",
        "\n",
        "def evolve():\n",
        "    GENERATIONS = 10\n",
        "    POPULATION_SIZE = 20\n",
        "\n",
        "    print(f\">>> INITIALIZING GENETIC ALGORITHM ({GENERATIONS} Gens, {POPULATION_SIZE} Pop)\")\n",
        "    print(\">>> Objective: Maximize Compression Ratio on Lorenz Attractor\")\n",
        "\n",
        "    # 1. Genesis\n",
        "    population = []\n",
        "    for _ in range(POPULATION_SIZE):\n",
        "        dna = BrainDNA(\n",
        "            n_reservoir=500, # Keep small for fast evolution\n",
        "            spectral_radius=random.uniform(0.5, 1.5),\n",
        "            leak_rate=random.uniform(0.1, 1.0),\n",
        "            input_scaling=random.uniform(0.1, 1.0),\n",
        "            forgetting=random.uniform(0.98, 1.0)\n",
        "        )\n",
        "        population.append(dna)\n",
        "\n",
        "    best_dna = None\n",
        "    best_fitness = 0\n",
        "\n",
        "    for gen in range(GENERATIONS):\n",
        "        print(f\"\\n--- GENERATION {gen+1} ---\")\n",
        "\n",
        "        scores = []\n",
        "        for i, dna in enumerate(population):\n",
        "            fitness = run_simulation(dna)\n",
        "            scores.append((fitness, dna))\n",
        "            sys.stdout.write(f\"\\rSubject {i+1}/{POPULATION_SIZE} | Fitness (Ratio): {fitness:.2f}x\")\n",
        "\n",
        "        # Sort by fitness (descending)\n",
        "        scores.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        top_fitness = scores[0][0]\n",
        "        avg_fitness = sum(s[0] for s in scores) / len(scores)\n",
        "\n",
        "        print(f\"\\nTop Ratio: {top_fitness:.2f}x | Avg: {avg_fitness:.2f}x\")\n",
        "        print(f\"Best DNA: Rad={scores[0][1].spectral_radius:.2f}, Leak={scores[0][1].leak_rate:.2f}, Scale={scores[0][1].input_scaling:.2f}\")\n",
        "\n",
        "        if top_fitness > best_fitness:\n",
        "            best_fitness = top_fitness\n",
        "            best_dna = copy.deepcopy(scores[0][1])\n",
        "\n",
        "        # Selection (Survival of the fittest)\n",
        "        survivors = scores[:POPULATION_SIZE//4] # Top 25%\n",
        "\n",
        "        # Breeding\n",
        "        new_population = []\n",
        "        while len(new_population) < POPULATION_SIZE:\n",
        "            # Pick a random survivor\n",
        "            parent_dna = random.choice(survivors)[1]\n",
        "            child_dna = copy.deepcopy(parent_dna)\n",
        "            child_dna.mutate()\n",
        "            new_population.append(child_dna)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"EVOLUTION COMPLETE\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"Ultimate Ratio Achieved: {best_fitness:.2f}x\")\n",
        "    print(\"Optimal Brain DNA:\")\n",
        "    print(best_dna)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    evolve()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7afzQ8Bkefyq",
        "outputId": "4eda17f4-1ee0-47cf-93a0-907b5322b72c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Evolutionary Environment: cuda\n",
            ">>> INITIALIZING GENETIC ALGORITHM (10 Gens, 20 Pop)\n",
            ">>> Objective: Maximize Compression Ratio on Lorenz Attractor\n",
            "\n",
            "--- GENERATION 1 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.37x\n",
            "Top Ratio: 1.67x | Avg: 1.42x\n",
            "Best DNA: Rad=0.92, Leak=0.13, Scale=0.30\n",
            "\n",
            "--- GENERATION 2 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.41x\n",
            "Top Ratio: 1.69x | Avg: 1.52x\n",
            "Best DNA: Rad=1.14, Leak=0.12, Scale=0.40\n",
            "\n",
            "--- GENERATION 3 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.64x\n",
            "Top Ratio: 1.73x | Avg: 1.64x\n",
            "Best DNA: Rad=1.07, Leak=0.02, Scale=0.28\n",
            "\n",
            "--- GENERATION 4 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.66x\n",
            "Top Ratio: 1.72x | Avg: 1.67x\n",
            "Best DNA: Rad=1.15, Leak=0.06, Scale=0.30\n",
            "\n",
            "--- GENERATION 5 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.64x\n",
            "Top Ratio: 1.73x | Avg: 1.68x\n",
            "Best DNA: Rad=1.15, Leak=0.02, Scale=0.32\n",
            "\n",
            "--- GENERATION 6 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.69x\n",
            "Top Ratio: 1.72x | Avg: 1.69x\n",
            "Best DNA: Rad=1.27, Leak=0.01, Scale=0.30\n",
            "\n",
            "--- GENERATION 7 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.69x\n",
            "Top Ratio: 1.76x | Avg: 1.69x\n",
            "Best DNA: Rad=1.27, Leak=0.01, Scale=0.30\n",
            "\n",
            "--- GENERATION 8 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.69x\n",
            "Top Ratio: 1.73x | Avg: 1.70x\n",
            "Best DNA: Rad=1.02, Leak=0.02, Scale=0.25\n",
            "\n",
            "--- GENERATION 9 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.69x\n",
            "Top Ratio: 1.74x | Avg: 1.69x\n",
            "Best DNA: Rad=1.09, Leak=0.03, Scale=0.18\n",
            "\n",
            "--- GENERATION 10 ---\n",
            "Subject 20/20 | Fitness (Ratio): 1.67x\n",
            "Top Ratio: 1.74x | Avg: 1.70x\n",
            "Best DNA: Rad=1.09, Leak=0.03, Scale=0.18\n",
            "\n",
            "========================================\n",
            "EVOLUTION COMPLETE\n",
            "========================================\n",
            "Ultimate Ratio Achieved: 1.76x\n",
            "Optimal Brain DNA:\n",
            "BrainDNA(n_reservoir=500, spectral_radius=np.float64(1.2658644139980693), leak_rate=np.float64(0.01), input_scaling=0.30205221796486803, forgetting=np.float64(0.9898105912031782))\n"
          ]
        }
      ]
    }
  ]
}